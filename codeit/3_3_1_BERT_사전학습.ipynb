{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumshin-dev/python_conda_jupyter/blob/main/codeit/3_3_1_BERT_%E1%84%89%E1%85%A1%E1%84%8C%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ì‚¬ì „ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì„¸íŠ¸ êµ¬ì„±\n",
        "\n",
        "BERT ëª¨ë¸ì€ ì‚¬ì „í•™ìŠµê³¼ ë¯¸ì„¸ì¡°ì •(Fine-Tuning)ì´ í™•ì‹¤í•˜ê²Œ ë‚˜ëˆ ì§€ëŠ” ëŒ€í‘œì ì¸ ëª¨ë¸ì…ë‹ˆë‹¤.  \n",
        "ë¯¸ì„¸ì¡°ì •ì€ ìì—°ì–´ Taskì— ë”°ë¼ ë‹¤ì–‘í•˜ê²Œ ì§„í–‰ ë  ìˆ˜ ìˆì§€ë§Œ, ì‚¬ì „ í•™ìŠµì€ ëŒ€ë¶€ë¶„ NSP í•™ìŠµê³¼ MLM í•™ìŠµìœ¼ë¡œ ì§„í–‰ì´ ë©ë‹ˆë‹¤.   \n",
        "\n",
        "í•´ë‹¹ ì˜ˆì‹œì—ì„œëŠ” [AIHUB](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=86) í•œêµ­ì–´ ê°ì„± ëŒ€í™” ë§ë­‰ì¹˜ë¥¼ ë¶€ë¶„ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì§ˆì˜->ì‘ë‹µ ìœ¼ë¡œ NSPì™€ MLM ì‚¬ì „ í•™ìŠµì„ ë™ì‹œ ì§„í–‰í•´ë´…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "vM8eWQ-SwbTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qxAdL36pweiU",
        "outputId": "4f50bb28-d148-4743-bd33-fb91b3294902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62616ffb-99d9-43cb-87df-1402832636d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62616ffb-99d9-43cb-87df-1402832636d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ShEXrR17xHD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f'./train.csv')\n",
        "df[['HS01','SS01']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "f7ERuUGMxVKP",
        "outputId": "a7c3f94c-6b11-43ab-f695-da85a0366edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    HS01  \\\n",
              "0                              ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤.   \n",
              "1         ì´ë²ˆ ë‹¬ì— ë˜ ê¸‰ì—¬ê°€ ê¹ì˜€ì–´! ë¬¼ê°€ëŠ” ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ë§Œ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ë‚˜.   \n",
              "2      íšŒì‚¬ì— ì‹ ì…ì´ ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ê°€ ê±°ìŠ¬ë ¤. ê·¸ëŸ° ì• ë¥¼ ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê°í•˜ë‹ˆê¹Œ ìŠ¤...   \n",
              "3      ì§ì¥ì—ì„œ ë§‰ë‚´ë¼ëŠ” ì´ìœ ë¡œ ë‚˜ì—ê²Œë§Œ ì˜¨ê°– ì‹¬ë¶€ë¦„ì„ ì‹œì¼œ. ì¼ë„ ë§ì€ ë° ì •ë§ ë¶„í•˜ê³  ...   \n",
              "4                  ì–¼ë§ˆ ì „ ì…ì‚¬í•œ ì‹ ì…ì‚¬ì›ì´ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ë‚˜.   \n",
              "...                                                  ...   \n",
              "51623     ë‚˜ì´ê°€ ë¨¹ê³  ì´ì œ ëˆë„ ëª» ë²Œì–´ ì˜¤ë‹ˆê¹Œ ì–´ë–»ê²Œ ì‚´ì•„ê°€ì•¼ í• ì§€ ë§‰ë§‰í•´. ëŠ¥ë ¥ë„ ì—†ê³ .   \n",
              "51624        ëª¸ì´ ë§ì´ ì•½í•´ì¡Œë‚˜ ë´. ì´ì œ ì „ê³¼ ê°™ì´ ì¼í•˜ì§€ ëª»í•  ê²ƒ ê°™ì•„ ë„ˆë¬´ ì§œì¦ ë‚˜.   \n",
              "51625   ì´ì œ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´. ë‚¨í¸ë„ ê·¸ë ‡ê³  ë…¸í›„ ì¤€ë¹„ë„ ì•ˆ ë˜ì–´ì„œ ë¯¸ë˜ê°€ ê±±ì •ë¼.   \n",
              "51626  ëª‡ì‹­ ë…„ì„ í•¨ê»˜ ì‚´ì•˜ë˜ ë‚¨í¸ê³¼ ì´í˜¼í–ˆì–´. ê·¸ë™ì•ˆì˜ ì„¸ì›”ì— ë°°ì‹ ê°ì„ ëŠë¼ê³  ë„ˆë¬´ í™”ê°€ ë‚˜.   \n",
              "51627  ë‚¨í¸ê³¼ ê²°í˜¼í•œ ì§€ ì‚¬ì‹­ ë…„ì´ì•¼. ì´ì œ ì‚¬ëŒ ë§Œë‚˜ëŠ” ê²ƒë„ ë²„ê²ê³  ì•Œë˜ ì‚¬ëŒë„ ì ì  ì‚¬ë¼ì ¸.   \n",
              "\n",
              "                                                    SS01  \n",
              "0                            ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ì£¼ìœ„ì— ì˜ë…¼í•  ìƒëŒ€ê°€ ìˆë‚˜ìš”?  \n",
              "1               ê¸‰ì—¬ê°€ ì¤„ì–´ ì†ìƒí•˜ì‹œê² ì–´ìš”. ì›”ê¸‰ì´ ì¤„ì–´ë“  ê²ƒì„ ì–´ë–»ê²Œ ë³´ì™„í•˜ì‹¤ ê±´ê°€ìš”?  \n",
              "2      íšŒì‚¬ ë™ë£Œ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ëŠ” ê²ƒ ê°™ì•„ìš”. ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ ...  \n",
              "3      ê´€ë ¨ ì—†ëŠ” ì‹¬ë¶€ë¦„ì„ ëª¨ë‘ í•˜ê²Œ ë˜ì–´ì„œ ë…¸ì—¬ìš°ì‹œêµ°ìš”. ì–´ë–¤ ê²ƒì´ ìƒí™©ì„ ë‚˜ì•„ì§ˆ ìˆ˜ ìˆ...  \n",
              "4      ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì€ íƒœë„ì— í™”ê°€ ë‚˜ì…¨êµ°ìš”. ìƒëŒ€ë°©ì˜ ì–´ë–¤ í–‰ë™ì´ ê·¸ëŸ° ê°ì •ì„ ìœ ë°œí•˜ëŠ”...  \n",
              "...                                                  ...  \n",
              "51623                 ê²½ì œì ì¸ ë¬¸ì œ ë•Œë¬¸ì— ë§‰ë§‰í•˜ì‹œêµ°ìš”. ë§ˆìŒì´ í¸ì¹˜ ì•Šìœ¼ì‹œê² ì–´ìš”.  \n",
              "51624              ê±´ê°•ì— ëŒ€í•œ ì–´ë ¤ì›€ ë•Œë¬¸ì— ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šìœ¼ì‹œêµ°ìš”. ì†ìƒí•˜ì‹œê² ì–´ìš”.  \n",
              "51625                      ë…¸í›„ ì¤€ë¹„ì— ëŒ€í•œ ì–´ë ¤ì›€ ë•Œë¬¸ì— ê±±ì •ì´ ë§ìœ¼ì‹œê² ì–´ìš”.  \n",
              "51626                               ê°€ì¡±ê³¼ì˜ ë¬¸ì œ ë•Œë¬¸ì— ì†ìƒí•˜ì‹œê² ì–´ìš”.  \n",
              "51627                    ëŒ€ì¸ê´€ê³„ì— ëŒ€í•œ ì–´ë ¤ì›€ ë•Œë¬¸ì— ê±±ì •ë˜ì‹œê³  ì†ìƒí•˜ì‹œê² ì–´ìš”.  \n",
              "\n",
              "[51628 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-141de476-aa77-46fe-af6d-fb72f965e412\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HS01</th>\n",
              "      <th>SS01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤.</td>\n",
              "      <td>ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ì£¼ìœ„ì— ì˜ë…¼í•  ìƒëŒ€ê°€ ìˆë‚˜ìš”?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ì´ë²ˆ ë‹¬ì— ë˜ ê¸‰ì—¬ê°€ ê¹ì˜€ì–´! ë¬¼ê°€ëŠ” ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ë§Œ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ë‚˜.</td>\n",
              "      <td>ê¸‰ì—¬ê°€ ì¤„ì–´ ì†ìƒí•˜ì‹œê² ì–´ìš”. ì›”ê¸‰ì´ ì¤„ì–´ë“  ê²ƒì„ ì–´ë–»ê²Œ ë³´ì™„í•˜ì‹¤ ê±´ê°€ìš”?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>íšŒì‚¬ì— ì‹ ì…ì´ ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ê°€ ê±°ìŠ¬ë ¤. ê·¸ëŸ° ì• ë¥¼ ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê°í•˜ë‹ˆê¹Œ ìŠ¤...</td>\n",
              "      <td>íšŒì‚¬ ë™ë£Œ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ëŠ” ê²ƒ ê°™ì•„ìš”. ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ì§ì¥ì—ì„œ ë§‰ë‚´ë¼ëŠ” ì´ìœ ë¡œ ë‚˜ì—ê²Œë§Œ ì˜¨ê°– ì‹¬ë¶€ë¦„ì„ ì‹œì¼œ. ì¼ë„ ë§ì€ ë° ì •ë§ ë¶„í•˜ê³  ...</td>\n",
              "      <td>ê´€ë ¨ ì—†ëŠ” ì‹¬ë¶€ë¦„ì„ ëª¨ë‘ í•˜ê²Œ ë˜ì–´ì„œ ë…¸ì—¬ìš°ì‹œêµ°ìš”. ì–´ë–¤ ê²ƒì´ ìƒí™©ì„ ë‚˜ì•„ì§ˆ ìˆ˜ ìˆ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ì–¼ë§ˆ ì „ ì…ì‚¬í•œ ì‹ ì…ì‚¬ì›ì´ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ë‚˜.</td>\n",
              "      <td>ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì€ íƒœë„ì— í™”ê°€ ë‚˜ì…¨êµ°ìš”. ìƒëŒ€ë°©ì˜ ì–´ë–¤ í–‰ë™ì´ ê·¸ëŸ° ê°ì •ì„ ìœ ë°œí•˜ëŠ”...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51623</th>\n",
              "      <td>ë‚˜ì´ê°€ ë¨¹ê³  ì´ì œ ëˆë„ ëª» ë²Œì–´ ì˜¤ë‹ˆê¹Œ ì–´ë–»ê²Œ ì‚´ì•„ê°€ì•¼ í• ì§€ ë§‰ë§‰í•´. ëŠ¥ë ¥ë„ ì—†ê³ .</td>\n",
              "      <td>ê²½ì œì ì¸ ë¬¸ì œ ë•Œë¬¸ì— ë§‰ë§‰í•˜ì‹œêµ°ìš”. ë§ˆìŒì´ í¸ì¹˜ ì•Šìœ¼ì‹œê² ì–´ìš”.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51624</th>\n",
              "      <td>ëª¸ì´ ë§ì´ ì•½í•´ì¡Œë‚˜ ë´. ì´ì œ ì „ê³¼ ê°™ì´ ì¼í•˜ì§€ ëª»í•  ê²ƒ ê°™ì•„ ë„ˆë¬´ ì§œì¦ ë‚˜.</td>\n",
              "      <td>ê±´ê°•ì— ëŒ€í•œ ì–´ë ¤ì›€ ë•Œë¬¸ì— ê¸°ë¶„ì´ ì¢‹ì§€ ì•Šìœ¼ì‹œêµ°ìš”. ì†ìƒí•˜ì‹œê² ì–´ìš”.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51625</th>\n",
              "      <td>ì´ì œ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´. ë‚¨í¸ë„ ê·¸ë ‡ê³  ë…¸í›„ ì¤€ë¹„ë„ ì•ˆ ë˜ì–´ì„œ ë¯¸ë˜ê°€ ê±±ì •ë¼.</td>\n",
              "      <td>ë…¸í›„ ì¤€ë¹„ì— ëŒ€í•œ ì–´ë ¤ì›€ ë•Œë¬¸ì— ê±±ì •ì´ ë§ìœ¼ì‹œê² ì–´ìš”.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51626</th>\n",
              "      <td>ëª‡ì‹­ ë…„ì„ í•¨ê»˜ ì‚´ì•˜ë˜ ë‚¨í¸ê³¼ ì´í˜¼í–ˆì–´. ê·¸ë™ì•ˆì˜ ì„¸ì›”ì— ë°°ì‹ ê°ì„ ëŠë¼ê³  ë„ˆë¬´ í™”ê°€ ë‚˜.</td>\n",
              "      <td>ê°€ì¡±ê³¼ì˜ ë¬¸ì œ ë•Œë¬¸ì— ì†ìƒí•˜ì‹œê² ì–´ìš”.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51627</th>\n",
              "      <td>ë‚¨í¸ê³¼ ê²°í˜¼í•œ ì§€ ì‚¬ì‹­ ë…„ì´ì•¼. ì´ì œ ì‚¬ëŒ ë§Œë‚˜ëŠ” ê²ƒë„ ë²„ê²ê³  ì•Œë˜ ì‚¬ëŒë„ ì ì  ì‚¬ë¼ì ¸.</td>\n",
              "      <td>ëŒ€ì¸ê´€ê³„ì— ëŒ€í•œ ì–´ë ¤ì›€ ë•Œë¬¸ì— ê±±ì •ë˜ì‹œê³  ì†ìƒí•˜ì‹œê² ì–´ìš”.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51628 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-141de476-aa77-46fe-af6d-fb72f965e412')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-141de476-aa77-46fe-af6d-fb72f965e412 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-141de476-aa77-46fe-af6d-fb72f965e412');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-29f8b1bd-16ca-4763-9daa-4e67ecc04761\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29f8b1bd-16ca-4763-9daa-4e67ecc04761')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-29f8b1bd-16ca-4763-9daa-4e67ecc04761 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['HS01','SS01']]\",\n  \"rows\": 51628,\n  \"fields\": [\n    {\n      \"column\": \"HS01\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51600,\n        \"samples\": [\n          \"\\ub0a8\\ud3b8\\uc774 \\ubc8c\\uc5b4\\uc624\\ub294 \\ub3c8\\ub9cc\\uc73c\\ub85c\\ub294 \\ub109\\ub109\\uc9c0\\uac00 \\uc54a\\uc544\\uc11c \\uc77c\\uc744 \\uc54c\\uc544\\ubcf4\\uace0 \\uc788\\ub294\\ub370 \\ud560 \\uc218 \\uc788\\ub294 \\uc77c\\uc774 \\uc5c6\\uc5b4.\",\n          \"\\ub098\\ub294 \\ud328\\ubc30\\uc790\\uc57c.\",\n          \"\\uc624\\ub298 \\uc624\\ub79c\\ub9cc\\uc5d0 \\ub300\\ud559 \\ub3d9\\uae30\\ub4e4\\uacfc \\uc800\\ub141 \\uba39\\uae30\\ub85c \\ud55c \\ub0a0\\uc774\\uc57c. \\uac04\\ub9cc\\uc5d0 \\uce5c\\uad6c\\ub4e4 \\ubcfc \\uc0dd\\uac01\\ud558\\ub2c8 \\ub108\\ubb34 \\uae30\\ubd84 \\uc88b\\uc544.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SS01\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50352,\n        \"samples\": [\n          \"\\uac70\\uc561\\uc744 \\uc190\\uc5d0 \\uc950\\uac8c \\ub418\\uc5b4 \\ubd88\\uc548\\ud558\\uba74\\uc11c\\ub3c4 \\ub5a8\\ub9ac\\uc2dc\\uaca0\\uc5b4\\uc694.\",\n          \"\\ub0a8\\ud3b8\\ubd84\\uc774 \\uc9d1\\uc548\\uc77c\\uc744 \\uc798\\ud55c\\ub2e4\\uace0 \\uc8fc\\uc7a5\\ud574\\uc11c \\ud669\\ub2f9\\ud558\\uc2dc\\uad70\\uc694.\",\n          \"\\uacb0\\ud63c \\uc900\\ube44\\uc758 \\uc5b4\\ub5a4 \\ubd80\\ubd84\\uc5d0 \\ub9c8\\uc74c\\uc774 \\ubd88\\ud3b8\\ud558\\uc2e0\\uac00\\uc694? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1XBYjjqMckBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NSP í•™ìŠµì„ ìœ„í•œ ë‘ë¬¸ì¥ í† í°\n",
        "\n",
        "BERT ì‚¬ì „í•™ìŠµì— ìˆì–´ì„œ ë¨¼ì € NSP í•™ìŠµì´ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´ 2ê°œì˜ ë¬¸ì¥ì„ ì—°ê²°í•˜ì—¬ ì ì ˆí•˜ê²Œ ì—°ê²°ëœ ë¬¸ì¥ê³¼ ë¹„ì ì ˆí•˜ê²Œ ì—°ê²°ëœ ë¬¸ì¥ì„ ì´ì§„ ë¶„ë¥˜ í•  ìˆ˜ ìˆê²Œ êµ¬ì„±í•´ ì¤ë‹ˆë‹¤.  \n",
        "\n",
        "ì´ë•Œ ë°ì´í„°ì„¸íŠ¸ì—ì„œ ë§Œë“¤ ìµœì¢… í† í°ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    ì‹œì‘í† í°[CLS] + ë¬¸ì¥1 í† í°+ êµ¬ë¶„í† í°[SEP] + ë¬¸ì¥2 í† í° + êµ¬ë¶„(ì¢…ë£Œ)í† í°[SEP]\n",
        "\n",
        "    ì˜ˆì‹œ: [CLS], ì˜¤ëŠ˜, ìˆ˜ì—…, ë­ì§€, [SEP], ìì—°ì–´, ë¶„ì„, ìˆ˜ì—…, [SEP]\n",
        "\n",
        "ì´ë ‡ê²Œ í† í°ì´ BERT ì…ë ¥ë˜ë©´ [CLS] í† í°ì€ ëª¨ë“  í† í°ê³¼ì˜ ì—°ê´€ì„±ì´ í¬í•¨ë˜ê¸° ë•Œë¬¸ì— [CLS] í† í°ìœ¼ë¡œ ë¬¸ì¥ì˜ ì—°ê²°ì´ ì ì ˆí•œì§€ ë¶„ë¥˜ê°€ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤.  \n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1N1r3JPdmIxXK6QxJASuN_ABpWkgfjm0I\" width=\"400\"/></center>\n",
        "\n",
        "ì˜ˆì‹œì—ì„œëŠ” `sentencepiece` í† í°í™”ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ê¸°ì¡´ì— ìˆëŠ” ìŠ¤í˜ì…œ í† í°ì¸ `bos`ë¥¼ `CLS`ë¡œ `eos`ë¥¼ `SEP`ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FGxS7IaAxe5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BPE :ë°”ì´íŠ¸ í˜ì–´ ì¸ì½”ë”©(Byte Pair Encoding, BPE)\n",
        "import os, re\n",
        "\n",
        "# ì¶”ê°€ ì“°ê¸°ëª¨ë“œë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ê¸°\n",
        "with open('train.txt', 'w', encoding='utf-8') as f:\n",
        "  for text in df['HS01']:\n",
        "        text = str(text)\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)     # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "        text = re.sub(r'[\\n\\t]', ' ', text)     # ì¤„ë°”ê¿ˆ, íƒ­ ì œê±°\n",
        "        text = re.sub(r'\\s+', ' ', text)        # ì—°ì†ëœ ê³µë°± ì œê±°\n",
        "        text= text.strip()                      # ë¬¸ì¥ ì–‘ë ê³µë°± ì œê±°\n",
        "        try:\n",
        "            f.write(text+'\\n')\n",
        "        except:\n",
        "                pass\n",
        "\n",
        "# ì €ì¥ ê²½ë¡œ ìƒì„±\n",
        "os.makedirs('./bpe', exist_ok=True)\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='train.txt',                      # í…ìŠ¤íŠ¸ ë­‰ì¹˜ íŒŒì¼\n",
        "    model_prefix='./bpe/spm_krsent',        # ì¶œë ¥ ëª¨ë¸ íŒŒì¼ ì´ë¦„\n",
        "    vocab_size=2000                         # í† í° ê°œìˆ˜\n",
        ")\n",
        "\n",
        "spm.SentencePieceTrainer.train(input='train.txt',               # í…ìŠ¤íŠ¸ ë­‰ì¹˜ íŒŒì¼\n",
        "                            model_prefix='./bpe/spm_krsent',    # ì¶œë ¥ ëª¨ë¸ íŒŒì¼ ì´ë¦„\n",
        "                            vocab_size=4000,                    # í† í° ê°œìˆ˜\n",
        "                            bos_id=1,\n",
        "                            eos_id=2,\n",
        "                            unk_id=3,\n",
        "                            pad_id=0\n",
        "                            )"
      ],
      "metadata": {
        "id": "9seJ8dGq5je-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SPDataSet(Dataset):\n",
        "    def __init__(self, sp, max_len):\n",
        "        self.max_len = max_len\n",
        "        self.df = pd.read_csv(f'./train.csv')\n",
        "        self.sp = sp\n",
        "\n",
        "        # ë‘ê°œì˜ ë¬¸ì¥ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸\n",
        "        self.pairs = []\n",
        "\n",
        "        # ì ì ˆí•˜ê²Œ ì—°ê²°ë˜ ë¬¸ì¥ì€ ë¼ë²¨ 1ë¡œ ì„¤ì •\n",
        "        for _, item in df.iterrows():\n",
        "            sent1 = item['HS01']\n",
        "            sent2 = item['SS01']\n",
        "            self.pairs.append((sent1, sent2, 1))\n",
        "\n",
        "        # ë¹„ì ì ˆí•œ ì—°ê²°ì„ ë§Œë“¤ê¸° ìœ„í•´ ëœë¤í•œ ì¸ë±ìŠ¤ ìƒì„±\n",
        "        n_lines = len(df)\n",
        "        rand_indices = np.random.randint(0, n_lines, size=(n_lines-1,))\n",
        "\n",
        "        # ëœë¤í•˜ê²Œ ì—°ê²°ëœ ë¬¸ì¥ì€ ë¼ë²¨ì„ 0ìœ¼ë¡œ ì„¤ì •\n",
        "        for i, rand_idx in enumerate(rand_indices):\n",
        "            if i == rand_idx:\n",
        "                continue\n",
        "            sent1 = df.iloc[i]['HS01']\n",
        "            sent2 = df.iloc[rand_idx]['SS01']\n",
        "            self.pairs.append((sent1, sent2, 0))\n",
        "\n",
        "        # ì•ë’¤ 10ê°œ ë¬¸ì¥ìŒ\n",
        "        print(self.pairs[:10])\n",
        "        print(self.pairs[-10:])\n",
        "\n",
        "    # ì œë¡œ íŒ¨ë”©ìœ¼ ìœ„í•œ í•¨ìˆ˜\n",
        "    def zero_pad(self, tok):\n",
        "        if len(tok) >= self.max_len:\n",
        "            return tok[:self.max_len]\n",
        "        else:\n",
        "            padding = np.zeros(self.max_len)\n",
        "            padding[:len(tok)] = tok\n",
        "            return padding\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        sent1, sent2, label = self.pairs[i]\n",
        "        sent1 = self.sp.encode_as_ids(sent1)\n",
        "        sent2 = self.sp.encode_as_ids(sent2)\n",
        "\n",
        "        # ë‘ê°œì˜ ë¬¸ì¥ì„ bos, eos í† í°ê³¼ í•¨ê»˜ ì—°ê²°\n",
        "        inp = [self.sp.bos_id()] + sent1 + [self.sp.eos_id()] + sent2 + [self.sp.eos_id()]\n",
        "\n",
        "        # íŒ¨ë”© ìƒì„±\n",
        "        inp = self.zero_pad(inp)\n",
        "\n",
        "        # íŒ¨ë”© ë§ˆìŠ¤í¬ ìƒì„±\n",
        "        mask = torch.eq(torch.Tensor(inp), 0)   # inp í…ì„œ ì•ˆì— ê°’ì´ 0ì¸ì§€ ë¹„êµí•´ì„œ True/Falseë¡œ ì´ë£¨ì–´ì§„ í…ì„œë¥¼ ë§Œë“ ë‹¤\n",
        "\n",
        "        return torch.Tensor(inp), label, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.pairs))\n",
        "\n",
        "sp = spm.SentencePieceProcessor(model_file=f'./bpe/spm_krsent.model')\n",
        "dataset = SPDataSet(sp, 60)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "for inp, tar, mask in dataloader:\n",
        "    print(f'ì…ë ¥ í† í° : {inp.long()}')\n",
        "    print(f'NSP ë¼ë²¨ : {tar}')\n",
        "    print(f'íŒ¨ë”© ë§ˆìŠ¤í¬ : {mask}')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWDXITyPxfjE",
        "outputId": "b4c82259-e4cf-4c03-da5e-e2e700486d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤.', 'ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ì£¼ìœ„ì— ì˜ë…¼í•  ìƒëŒ€ê°€ ìˆë‚˜ìš”?', 1), ('ì´ë²ˆ ë‹¬ì— ë˜ ê¸‰ì—¬ê°€ ê¹ì˜€ì–´! ë¬¼ê°€ëŠ” ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ë§Œ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ë‚˜.', 'ê¸‰ì—¬ê°€ ì¤„ì–´ ì†ìƒí•˜ì‹œê² ì–´ìš”. ì›”ê¸‰ì´ ì¤„ì–´ë“  ê²ƒì„ ì–´ë–»ê²Œ ë³´ì™„í•˜ì‹¤ ê±´ê°€ìš”?', 1), ('íšŒì‚¬ì— ì‹ ì…ì´ ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ê°€ ê±°ìŠ¬ë ¤. ê·¸ëŸ° ì• ë¥¼ ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê°í•˜ë‹ˆê¹Œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„. ', 'íšŒì‚¬ ë™ë£Œ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ëŠ” ê²ƒ ê°™ì•„ìš”. ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ í•˜ë©´ ì¢‹ì„ê¹Œìš”?', 1), ('ì§ì¥ì—ì„œ ë§‰ë‚´ë¼ëŠ” ì´ìœ ë¡œ ë‚˜ì—ê²Œë§Œ ì˜¨ê°– ì‹¬ë¶€ë¦„ì„ ì‹œì¼œ. ì¼ë„ ë§ì€ ë° ì •ë§ ë¶„í•˜ê³  ì„­ì„­í•´.', 'ê´€ë ¨ ì—†ëŠ” ì‹¬ë¶€ë¦„ì„ ëª¨ë‘ í•˜ê²Œ ë˜ì–´ì„œ ë…¸ì—¬ìš°ì‹œêµ°ìš”. ì–´ë–¤ ê²ƒì´ ìƒí™©ì„ ë‚˜ì•„ì§ˆ ìˆ˜ ìˆê²Œ ë„ì›€ì„ ì¤„ê¹Œìš”?', 1), ('ì–¼ë§ˆ ì „ ì…ì‚¬í•œ ì‹ ì…ì‚¬ì›ì´ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ë‚˜.', 'ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì€ íƒœë„ì— í™”ê°€ ë‚˜ì…¨êµ°ìš”. ìƒëŒ€ë°©ì˜ ì–´ë–¤ í–‰ë™ì´ ê·¸ëŸ° ê°ì •ì„ ìœ ë°œí•˜ëŠ” ê²ƒì¼ê¹Œìš”?', 1), ('ì§ì¥ì— ë‹¤ë‹ˆê³  ìˆì§€ë§Œ ì‹œê°„ë§Œ ë²„ë¦¬ëŠ” ê±° ê°™ì•„. ì§„ì§€í•˜ê²Œ ì§„ë¡œì— ëŒ€í•œ ê³ ë¯¼ì´ ìƒê²¨.', 'ì§„ë¡œì— ëŒ€í•´ì„œ ê³ ë¯¼í•˜ê³  ê³„ì‹œëŠ”êµ°ìš”. ì–´ë–¤ ì ì´ ê³ ë¯¼ì¸ê°€ìš”?', 1), ('ì„±ì¸ì¸ë°ë„ ì§„ë¡œë¥¼ ì•„ì§ë„ ëª» ì •í–ˆë‹¤ê³  ë¶€ëª¨ë‹˜ì´ ë…¸ì—¬ì›Œí•˜ì…”. ë‚˜ë„ ì„­ì„­í•´.', 'ë¶€ëª¨ë‹˜ì˜ ë…¸ì—¬ì›€ì— ì„­ì„­í•˜ì‹œêµ°ìš”. ì´ëŸ° ìƒí™©ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ë©´ ì¢‹ì„ê¹Œìš”? ', 1), ('í‡´ì‚¬í•œ ì§€ ì–¼ë§ˆ ì•ˆ ëì§€ë§Œ ì²œì²œíˆ ì§ì¥ì„ êµ¬í•´ë³´ë ¤ê³ .', 'ì²œì²œíˆë¼ë„ ì§ì¥ì„ êµ¬í•´ ë³´ë ¤ê³  í•˜ì‹œëŠ”êµ°ìš”. íŠ¹ë³„í•œ ì´ìœ ê°€ ìˆìœ¼ì‹ ê°€ìš”?', 1), ('ì¡¸ì—…ë°˜ì´ë¼ì„œ ì·¨ì—…ì„ ìƒê°í•´ì•¼ í•˜ëŠ”ë° ì§€ê¸ˆ ë„ˆë¬´ ëŠê¸‹í•´ì„œ ì´ë˜ë„ ë˜ë‚˜ ì‹¶ì–´.', 'ì·¨ì—…ì— ëŒ€í•´ ê±±ì •ì´ ë˜ëŠ”êµ°ìš”.', 1), ('ìš”ì¦˜ ì§ì¥ìƒí™œì´ ë„ˆë¬´ í¸í•˜ê³  ì¢‹ì€ ê²ƒ ê°™ì•„!', 'ì§ì¥ìƒí™œì´ í¸í•˜ê³  ì¢‹ìœ¼ì‹œë‹¤ë‹ˆ ì¢‹ì•„ ë³´ì—¬ìš”. ë‹¤ë‹ˆê³  ê³„ì‹  íšŒì‚¬ë§Œì˜ ì¥ì ì´ ìˆë‚˜ìš”?', 1)]\n",
            "[('ìš”ì¦˜ ë“¤ì–´ ë¶€ì© ëª¸ì´ ì•ˆ ì¢‹ì•„ì§„ ê±° ê°™ì•„. ì•„ì§ ì• ë“¤ë„ ë‹¤ ì•ˆ ì»¸ëŠ”ë° ê±±ì •ì´ ë¼.', 'ë§ì´ ì†ìƒí•´ ë³´ì´ëŠ”êµ°ìš”. ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆë‚˜ìš”?', 0), ('ëŠ™ì–´ê°€ëŠ” ê²Œ ëŠê»´ì ¸. ì´ì œ ì¼í•  ë•Œë„ í˜ì´ ë¶€ì¡±í•˜ë‹¨ ê±¸ ëŠê»´ì„œ ì†ìƒí•´.', 'í”„ë¡œì íŠ¸ ì‹¤íŒ¨ ë•Œë¬¸ì— ë§ì´ í˜ë“œì…¨êµ°ìš”.', 0), ('ë‚¨í¸ì´ ë‚´ ê³ì„ ë– ë‚¬ì–´. ì•„ë¬´ê²ƒë„ ëª» í•´ì¤€ ë‚´ê°€ ì‹¤ë§ìŠ¤ëŸ½ê³  ìê¾¸ ëˆˆë¬¼ì´ ë‚˜.', 'ìì‹ë“¤ì—ê²Œ ìœ í–‰ì–´ë¥¼ ì‚¬ìš©í–ˆë‹¤ê°€ ë°˜ì‘ì´ ì—†ì–´ ë¶€ë„ëŸ¬ìš°ì…¨êµ°ìš”.', 0), ('ê±´ê°•ê´€ë¦¬ë¥¼ ë„ˆë¬´ ì•ˆ í•´ì„œ ê±´ê°•ì´ ì¢‹ì§€ ì•Šì•„ ì¡Œì–´. ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ í ë¼ì¹ ê¹Œ ë´ ê±±ì •ë¼.', 'ì—´ì‹¬íˆ ì¼í•´ë„ ê¸‰ì—¬ê°€ ì˜¤ë¥´ì§€ ì•Šì„ ê²ƒ ê°™ì•„ ë¶ˆì•ˆê°ì´ ë“œëŠ”êµ°ìš”.', 0), ('ì´ì œ ëª¸ì´ ì ì  ì•½í•´ì§„ë‹¤ëŠ” ê²Œ ëŠê»´ì ¸. ì•„ë‚´ì—ê²Œ ë¯¸ì•ˆí•˜ê³  ì†ìƒí•œ ë§ˆìŒì´ ë“¤ì–´.', 'ì—°ë½ì´ ë‹¿ì§€ ì•ŠëŠ”ë‹¤ê³  ë„ˆë¬´ ì´ˆì¡°í•˜ì‹  ê±° ê°™ì•„ìš”.', 0), ('ë‚˜ì´ê°€ ë‹¤ ë¼ì„œ í‡´ì§ì„ í•˜ê²Œ ë˜ì—ˆì–´. í•˜ì§€ë§Œ ë…¸í›„ ì¤€ë¹„ë¥¼ ì œëŒ€ë¡œ ì•ˆ í•´ì„œ ëˆ ê±±ì •ì´ ì•ì„œ.', 'ì™œ ë²Œ ë°›ê³ ìˆë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?', 0), ('ë‚˜ì´ê°€ ë¨¹ê³  ì´ì œ ëˆë„ ëª» ë²Œì–´ ì˜¤ë‹ˆê¹Œ ì–´ë–»ê²Œ ì‚´ì•„ê°€ì•¼ í• ì§€ ë§‰ë§‰í•´. ëŠ¥ë ¥ë„ ì—†ê³ .', 'ë‹¤ë¥¸ ì´ë“¤ê³¼ ë¹„êµí•˜ê²Œ ë˜ì–´ í˜ë“œì‹œêµ°ìš”. ì¢€ ë” ë§ì”€í•´ì£¼ì„¸ìš”.', 0), ('ëª¸ì´ ë§ì´ ì•½í•´ì¡Œë‚˜ ë´. ì´ì œ ì „ê³¼ ê°™ì´ ì¼í•˜ì§€ ëª»í•  ê²ƒ ê°™ì•„ ë„ˆë¬´ ì§œì¦ ë‚˜.', 'ì‚¬ì¥ ì•„ë“¤ì´ë¼ëŠ” ì´ìœ ë¡œ ì›”ê¸‰ì„ ë§ì´ ë°›ì•„ í™˜ë©¸ì„ ëŠë¼ì…¨êµ°ìš”.', 0), ('ì´ì œ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´. ë‚¨í¸ë„ ê·¸ë ‡ê³  ë…¸í›„ ì¤€ë¹„ë„ ì•ˆ ë˜ì–´ì„œ ë¯¸ë˜ê°€ ê±±ì •ë¼.', 'ê²°í˜¼ì— ëŒ€í•œ ìƒê°ì´ ë§ì•„ì ¸ì„œ ê³ ë¯¼ì´ ë§ìœ¼ì‹ ê°€ ë´ìš”.', 0), ('ëª‡ì‹­ ë…„ì„ í•¨ê»˜ ì‚´ì•˜ë˜ ë‚¨í¸ê³¼ ì´í˜¼í–ˆì–´. ê·¸ë™ì•ˆì˜ ì„¸ì›”ì— ë°°ì‹ ê°ì„ ëŠë¼ê³  ë„ˆë¬´ í™”ê°€ ë‚˜.', 'ê·¸ëŸ° ì¼ì´ ìˆì—ˆêµ°ìš”.', 0)]\n",
            "ì…ë ¥ í† í° : tensor([[   1, 1695,  852,   26,   16,   65,   18,  184,  382, 3543,  957,   49,\n",
            "           91,  443,   16,  710,  205,  992,  486,    3,    2,  885, 2940,   50,\n",
            "          369,  382, 3543,  957,   49,  235, 1605,  760,  783,    3,   53, 1024,\n",
            "          143,  427,  783,    3,    2,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "NSP ë¼ë²¨ : tensor([1])\n",
            "íŒ¨ë”© ë§ˆìŠ¤í¬ : tensor([[False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLM í•™ìŠµì„ ìœ„í•œ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬\n",
        "\n",
        "MLM ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ëŠ” ë°ì´í„°ì„¸íŠ¸ ë‚´ë¶€ì—ì„œ ì§„í–‰í•˜ì§€ ì•Šê³  í•™ìŠµ ë¡œì§ì— ì ìš©í•  í•¨ìˆ˜ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.  \n",
        "\n",
        "NPS ë°ì´í„°ì„¸íŠ¸ ì¶œë ¥ì— ëœë¤í•˜ê²Œ 15í¼ì„¼íŠ¸ì˜ í† í°ì„ ì„ íƒí•˜ê³  ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ë¥¼ í•˜ë˜, ì„ íƒëœ ëª¨ë“  í† í°ì„ ë§ˆìŠ¤í‚¹ í•˜ì§€ ì•Šê³  ë‹¤ìŒ ê³¼ì •ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "    - ìŠ¤í˜ì…œ í† í°ì€ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ í•˜ì§€ ì•ŠìŒ\n",
        "    - 15í¼ì„¼íŠ¸ì¤‘ 80í¼ì„¼íŠ¸ë§Œ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬\n",
        "    - 15í¼ì„¼íŠ¸ì¤‘ 10í¼ì„¼íŠ¸ëŠ” ì„ì˜ì˜ ë‹¤ë¥¸ í† í°ìœ¼ë¡œ ë³€ê²½\n",
        "    - 15í¼ì„¼íŠ¸ì¤‘ 10í¼ì„¼íŠ¸ëŠ” ê¸°ì¡´ í† í° ìœ ì§€\n",
        "\n",
        "ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ê°€ ë¬ë‹¤ë©´ í•™ìŠµì„ ìœ„í•´ ë§ˆìŠ¤í‚¹ ë¶€ë¶„ì˜ í† í°ì„ ë¼ë²¨ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. ë§ˆìŠ¤í‚¹ ë¶€ë¶„ì„ ì‹¤ì œ í† í° ë²ˆí˜¸ë¡œ ë‚˜ë¨¸ì§€ ìœ„ì¹˜ëŠ” -100(ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” id)ë¡œ ì„¤ì •í•˜ì—¬ ë¬´ì‹œí•˜ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1xA_4jCYfaguZlqZtCH8nuJnVIixagdxq\" width=\"500\"/></center>\n",
        "\n",
        "\n",
        "ì˜ˆì‹œì—ì„œ ì‚¬ìš©í•˜ëŠ” sentencepiece ëª¨ë¸ì€ ë§ˆìŠ¤í¬ í† í°ì´ ë”°ë¡œ ì„¤ì •ë˜ì§€ ì•Šì•„ì„œ ë§ˆì§€ë§‰ í† í° idì— +1 í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "lkgofX6i-M0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_tokens_for_mlm(input_ids, special_tokens_ids, mask_token_id,\n",
        "                        vocab_size, mlm_prob=0.15):\n",
        "    \"\"\"\n",
        "    ğŸ§  ë™ì‘ ìˆœì„œ\n",
        "    1) ì…ë ¥ í…ì„œ í¬ê¸°(B,L) ê°€ì ¸ì˜¤ê¸°\n",
        "    2) mlm ë¼ë²¨(-100 ê¸°ë³¸ê°’) ì¤€ë¹„\n",
        "    3) special token ìœ„ì¹˜ ì²´í¬\n",
        "    4) 15% í† í° ë§ˆìŠ¤í‚¹í•  ìœ„ì¹˜ ì„ íƒ\n",
        "    5) (80/10/10) ê·œì¹™ì— ë”°ë¼ maskí•˜ê±°ë‚˜ randomí•˜ê±°ë‚˜ ê·¸ëŒ€ë¡œ\n",
        "    6) ìµœì¢… masked input + ì •ë‹µ ë¼ë²¨ ë°˜í™˜\n",
        "\n",
        "    100% í† í°\n",
        "    â””â”€â”€ 15% â†’ ë§ˆìŠ¤í‚¹ ëŒ€ìƒ (to_mask=True)\n",
        "      â”œâ”€â”€ 80% â†’ [MASK] í† í°ìœ¼ë¡œ ë°”ê¿ˆ\n",
        "      â”œâ”€â”€ 10% â†’ ëœë¤ í† í°ìœ¼ë¡œ ë°”ê¿ˆ\n",
        "      â””â”€â”€ 10% â†’ ì›ë˜ í† í° ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "\n",
        "    \"\"\"\n",
        "    device = input_ids.device\n",
        "    # 1) ì…ë ¥ í…ì„œ í¬ê¸°(B,L) ê°€ì ¸ì˜¤ê¸°\n",
        "    B, L = input_ids.shape                  # batch_size(ë¬¸ì¥ ê°¯ìˆ˜), seqnece_length(ê°ë¬¸ì¥ ê¸¸ì´)\n",
        "    masked_input_ids = input_ids.clone()\n",
        "\n",
        "    # 2) mlm ë¼ë²¨(-100 ê¸°ë³¸ê°’) ì¤€ë¹„\n",
        "    #   ë¼ë²¨ í† í°ì„ ìœ„í•´ ë™ì¼ í˜•ì‚¬ì˜ -100 í…ì„œ ìƒì„±\n",
        "    mlm_labels = torch.full_like(input_ids, -100)       # -100ì€ ë¼ë²¨ì—ì„œ ë¬´ì‹œë˜ëŠ” í† í°ìœ¼ë¡œ ì‚¬ìš©\n",
        "\n",
        "    # 3) special token ìœ„ì¹˜ ì²´í¬\n",
        "    #   ìŠ¤í˜ì…œ í† í° ìœ„ì¹˜ë¥¼ True\n",
        "    special_mask = torch.zeros_like(input_ids, dtype=torch.bool)\n",
        "    for sp_id in special_tokens_ids:\n",
        "        special_mask |= (input_ids == sp_id)\n",
        "\n",
        "    # 4) 15% í† í° ë§ˆìŠ¤í‚¹í•  ìœ„ì¹˜ ì„ íƒ\n",
        "    #   0~1 ì‚¬ì´ì˜ ë¬´ì‘ìœ„ í™•ë£° ë¶„í¬ ìƒì„±\n",
        "    #   mlm_prob(0.15)ë³´ë‹¤ ì‘ê³  ìŠ¤í˜ì…œ í† í°ì´ ì•„ë‹Œ ê²½ìš°ë§Œ\n",
        "    rand_vals = torch.rand_like(input_ids.float())\n",
        "    to_mask = (rand_vals < mlm_prob) & (~special_mask)\n",
        "    # print(f'ìŠ¤í˜ì…œ í† í°ì¸ ê²½ìš°: {special_mask}')\n",
        "    # print(f'mlm_prob(0.15)ë³´ë‹¤ ì‘ì€ ê²½ìš°: {rand_vals < mlm_prob}')\n",
        "\n",
        "    #   ë§ˆìŠ¤í‚¹ëœ ìœ„ì¹˜ì˜ ì •ë‹µ ë ˆì´ë¸” = ì›ë³¸ í† í°\n",
        "    mlm_labels[to_mask] = input_ids[to_mask]\n",
        "\n",
        "    # 5) (80/10/10) ê·œì¹™ì— ë”°ë¼ maskí•˜ê±°ë‚˜ randomí•˜ê±°ë‚˜ ê·¸ëŒ€ë¡œ\n",
        "    #   BERT ë…¼ë¬¸ ë¹„ìœ¨: 80% -> [MASK], 10% -> random,  10% -> ì›ë³¸\n",
        "    mask_choices = torch.rand_like(input_ids.float())\n",
        "\n",
        "    #   mask_choicesì—ì„œ 80%ì— í•´ë‹¹í•˜ê³  ë§ˆìŠ¤í¬ ì¸ë±ìŠ¤ì¸ ê²½ìš° ë§ˆìŠ¤í¬ í† í°ìœ¼ë¡œ\n",
        "    mask_1 = (mask_choices < 0.8) & to_mask\n",
        "    masked_input_ids[mask_1] = mask_token_id\n",
        "\n",
        "    #   mask_choicesì—ì„œ 10%ì— í•´ë‹¹í•˜ê³  ë§ˆìŠ¤í¬ ì¸ë±ìŠ¤ì¸ ê²½ìš° ëœë¤ í† í° ë³€í™˜\n",
        "    mask_2 = (mask_choices >= 0.8) & (mask_choices < 0.9) & to_mask\n",
        "    random_tokens = torch.randint(0, vocab_size, size=(), device=device)\n",
        "    masked_input_ids[mask_2] = random_tokens\n",
        "\n",
        "    # 6) ìµœì¢… masked input + ì •ë‹µ ë¼ë²¨ ë°˜í™˜\n",
        "    return masked_input_ids, mlm_labels\n",
        "\n",
        "mask_id = sp.get_piece_size()\n",
        "special_tokens_ids = [sp.bos_id(), sp.eos_id(), 0]\n",
        "for inp, tar, mask in dataloader:\n",
        "    print(f'ì…ë ¥ í† í° : {inp.long()}')\n",
        "    mlm_input, mlm_labels= mask_tokens_for_mlm(inp.long(), special_tokens_ids, mask_id, sp.get_piece_size())\n",
        "    print(f'MLM í† í° : {mlm_input}')\n",
        "    print(f'MLM ë¼ë²¨ : {mlm_labels}')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My9_BpEk-NkA",
        "outputId": "aa6d79dd-cbaf-4e91-cbaf-f369fcf246b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì…ë ¥ í† í° : tensor([[   1,   32,   10, 2120,  593,    6,    4, 3864, 1852,    3,    9,   51,\n",
            "            3,    2,  593,    6,    4, 3929, 3771,  168,  678,  137,   35,   32,\n",
            "           10,  726,  668,    7,  488, 1605,  760,  783,    3,    2,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "MLM í† í° : tensor([[   1, 4000,   10, 4000,  593,    6,    4, 3864, 1852,    3,    9,   51,\n",
            "            3,    2, 4000,    6,    4, 4000, 3771,  168, 4000, 4000,   35, 2565,\n",
            "           10,  726,  668,    7,  488, 4000,  760,  783,    3,    2,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "MLM ë¼ë²¨ : tensor([[-100,   32, -100, 2120, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "         -100, -100,  593, -100, -100, 3929, -100, -100,  678,  137, -100,   32,\n",
            "         -100, -100, -100, -100, -100, 1605, -100, -100, -100, -100, -100, -100,\n",
            "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT ëª¨ë¸ë§\n",
        "\n",
        "BERT ëª¨ë¸ì€ pytorchì˜ nn.MultiheadAttention ë ˆì´ì–´ë¥¼ í™œìš©í•˜ì—¬ Transformerì˜ ì¸ì½”ë”ì™€ ë™ì¼í•œ ì•„í‚¤í…ì²˜ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "YgHe9lLlI9Aj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ë©€í‹°í—¤ë“œ ë¸”ë¡\n",
        "\n",
        "ë¨¼ì € nn.MultiheadAttention -> Feed Forward êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” Trasnformerì˜ ì¸ì½”ë” í˜•ì‹ì˜ ë¸”ë¡ì„ ì •ì˜í•©ë‹ˆë‹¤.   \n",
        "Trasnformerì˜ ì¸ì½”ë”ì™€ ë™ì¼í•˜ê²Œ LayerNormê³¼ Skipë„ ì ìš©í•´ ì¤ë‹ˆë‹¤.\n",
        "\n",
        "nn.MultiheadAttention ë ˆì´ì–´ëŠ” ë§ˆìŠ¤í¬ë¥¼ ì…ë ¥í• ë•Œ `True` ì¸ ìœ„ì¹˜ê°€ ë§ˆìŠ¤í‚¹ ë˜ë¯€ë¡œ ì£¼ì˜í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "qbDH_opLI9pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MTBlock(nn.Module):\n",
        "    def __init__(self, em_dim, nhead, feed_dim=512, gelu=False, dropout=0.):\n",
        "        super(MTBlock, self).__init__()\n",
        "\n",
        "        # ë©€í‹° í—¤ë“œ\n",
        "        self.mha = nn.MultiheadAttention(em_dim, nhead, dropout=dropout, batch_first=True) # batch_first=True -> (batch, seq_len, embed)\n",
        "        self.nhead = nhead\n",
        "\n",
        "        # Fee Forward\n",
        "        if gelu:\n",
        "            self.active = nn.GELU()\n",
        "        else:\n",
        "            self.active = nn.ReLU()\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(em_dim, feed_dim),\n",
        "            self.active,\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(feed_dim, em_dim)\n",
        "        )\n",
        "\n",
        "        # ì •ê·œí™”\n",
        "        self.norm1 = nn.LayerNorm(em_dim, eps=1e-6)\n",
        "        self.norm2 = nn.LayerNorm(em_dim, eps=1e-6)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # ì…€í”„ ì–´í…ì…˜\n",
        "        attn_output, _ = self.mha(x, x, x, key_padding_mask=mask, need_weights=False)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.norm1(x + attn_output)\n",
        "\n",
        "        # FFN\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        out2 = self.norm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n",
        "\n",
        "x = torch.randn(3, 10, 32)\n",
        "te = MTBlock(32, 4, 128)\n",
        "out = te(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcSPoza1I_i7",
        "outputId": "7c4560e6-ce90-43da-ae6c-b7dbc6dc1773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### í¬ì§€ì…” ì¸ì½”ë”©\n",
        "\n",
        "BERT ë˜í•œ ì…ë ¥ëœ í† í°ì˜ ìˆœì„œë¥¼ ì¸ì§€í•˜ê¸° ìœ„í•´ í¬ì§€ì…˜ ì¸ì½”ë”© ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. Trasnformerì—ì„œ êµ¬í˜„í•œ í¬ì§€ì…˜ ì¸ì½”ë”©ì„ ë°©ì‹ì„ ëŒ€ê·œëª¨ ì—°ì‚°ì— ìœ ë¦¬í•˜ê²Œ pytorchì˜ í…ì„œ ì—°ì‚° ê³¼ì •ìœ¼ë¡œ ê°ì²´í™”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "- ìœ„ìƒ ê°ë„ ê³µì‹:\n",
        "\n",
        "<center>$angle = \\tfrac{pos}{10000^{\\,\\frac{2i}{d_{\\text{model}}}}}$</center>\n",
        "\n",
        "\n",
        "- ì§€ìˆ˜&ë¡œê·¸ ì‹ìœ¼ë¡œ í‘œí˜„ì‹œ:\n",
        "<center>$\\exp \\bigl( \\alpha \\cdot -\\log\\bigl(10000\\bigr) \\bigr)  = \\exp \\bigl( \\alpha \\cdot \\log\\bigl(\\tfrac{1}{10000}\\bigr) \\bigr) = \\frac{1}{10000^\\alpha}$</center>"
      ],
      "metadata": {
        "id": "dQzf84FXNJa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim, max_pos=10000):\n",
        "        super().__init__()\n",
        "        # ìœ„ì¹˜ ì¸ë±ìŠ¤\n",
        "        position = torch.arange(max_pos).unsqueeze(1)\n",
        "        # ìœ„ì¹˜ì— ë”°ë¥¸ ê°ë„ ì¶”ì¶œ\n",
        "        # ì§€ìˆ˜(exp)ì™€ ë¡œê·¸(log)ë¥¼ í•¨ê»˜ì¨ ì§€ìˆ˜ìŠ¹ í˜•íƒœ(**)ë¥¼ ë§Œë“¤ì–´ ì‚¬ìš©\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * (-math.log(10000.0) / embed_dim))\n",
        "\n",
        "        # ì œë¡œ í…ì„œë¥¼ ë§Œë“¤ê³  sin,cos ê²°ê³¼ í• ë‹¹\n",
        "        pe = torch.zeros(1, max_pos, embed_dim)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe) # í•™ìŠµë˜ì§€ ì•ŠëŠ” ëª¨ë“ˆë¡œ ì €ì¥\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ì„ë² ë”©ì´ ì…ë ¥ë˜ë©´ í¬ì§€ì…˜ê³¼ ë”í•˜ì—¬ ë°˜í™˜\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "pe = PositionalEncoding(32)\n",
        "x = torch.randn(3, 10, 32)\n",
        "pe(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoukZpszNK1K",
        "outputId": "7d7e4150-e752-4186-a356-7c6907bb51e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ìµœì¢… ëª¨ë¸ êµ¬í˜„\n",
        "\n",
        "ì…ë ¥ëœ í† í°ì„ ì„ë² ë”© í•˜ëŠ” `nn.Embedding` ë ˆì´ì–´ì™€ í¬ì§€ì…˜ ì¸ì½”ë”©, ë©€í‹°í—¤ë“œ ë¸”ë¡ì„ ìˆœì°¨ì ìœ¼ë¡œ í†µê³¼ì‹œí‚¤ëŠ” BERT ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.  \n",
        "\n",
        "ì´ë•Œ ë©€í‹°í—¤ë“œ ë¸”ë¡ì„ í†µê³¼í•œ ê²°ê³¼ ì„ë² ë”©ì„ í™œìš©í•˜ì—¬ MLM ì˜ˆì¸¡ì„ ìœ„í•œ ì„ í˜•ë ˆì´ì–´ì™€ CLSí† í°ì„ í†µí•´ ì´ì§„ë¶„ë¥˜ë¥¼ í•˜ëŠ” NSP ì„ í˜•ë ˆì´ì–´ ë‘ê°€ì§€ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.  "
      ],
      "metadata": {
        "id": "paTaSk-ENXCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleBERT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, num_heads=4,\n",
        "                 feed_dim=256, num_layers=4, num_classes=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # ì„ë² ë”© (Token + Position)\n",
        "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.pos_encoding = PositionalEncoding(embed_dim)\n",
        "\n",
        "        # ì—¬ëŸ¬ê°œì˜ Transformer Encoder Block\n",
        "        self.layers = nn.ModuleList([\n",
        "            MTBlock(embed_dim, num_heads, feed_dim, dropout=dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # MLM í—¤ë“œ(í† í°ë³„ vocab ë¶„ë¥˜)\n",
        "        self.mlm_head = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "        # NSP í—¤ë“œ([CLS] ìœ„ì¹˜ ì´ì§„ ë¶„ë¥˜)\n",
        "        self.nsp_head = nn.Linear(embed_dim, 2)\n",
        "\n",
        "    def forward(self, x, mask=None, mode='both'):\n",
        "        # x: (batch, seq_len)\n",
        "        batch_size, seq_len = x.shape\n",
        "        device = x.device\n",
        "\n",
        "        # ì„ë² ë”© + ìœ„ì¹˜ ì¸ì½”ë”©\n",
        "        emb = self.token_emb(x)\n",
        "\n",
        "        # Scaled Dot-Product Attention: ì ìˆ˜ ì•ˆì •í™”ë¥¼ ìœ„í•´ sqrt(embed_dim)ë¡œ ë‚˜ëˆ”\n",
        "        scale = torch.sqrt(torch.tensor(self.embed_dim, dtype=torch.float, device=device))\n",
        "        x = emb * scale\n",
        "        x = self.pos_encoding(x)\n",
        "        x = self.dropout(x)             # (batch, seq_len, embed_dim)\n",
        "\n",
        "        # Encoder Blockë“¤ì„ í†µê³¼\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        # MLM í—¤ë“œ í†µê³¼\n",
        "        mlm_logits = self.mlm_head(x)   # (B, L, vocab_size)\n",
        "\n",
        "        # CLS í† í°ìœ¼ë¡œ NSP í—¤ë“œ í†µê³¼\n",
        "        cls_emb = x[:, 0]               # (B, E)\n",
        "        nsp_logits = self.nsp_head(cls_emb)\n",
        "        return mlm_logits, nsp_logits\n",
        "\n",
        "vocab_size = sp.get_piece_size()\n",
        "model = SimpleBERT(vocab_size)\n",
        "with torch.no_grad():\n",
        "    for inp, tar, mask in dataloader:\n",
        "        mlm_logits, nsp_logits = model(inp.long(), mask)\n",
        "        print(mlm_logits.shape)\n",
        "        print(nsp_logits)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsLVaR_9NYYY",
        "outputId": "2cfc5c16-6211-4b90-a741-3bb7dda8d04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 60, 4000])\n",
            "tensor([[-0.1488,  0.0299]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ëª¨ë¸ í•™ìŠµí•˜ê¸°(MLM + NSP)\n",
        "\n",
        "êµ¬í˜„í•œ BERT ëª¨ë¸ê³¼ ë°ì´í„°ì„¸íŠ¸, MLM í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ MLM, NSP ì‚¬ì „í•™ìŠµì„ ë™ì‹œì— ì§„í–‰í•©ë‹ˆë‹¤. ë”°ë¼ì„œ MLM ì˜ˆì¸¡ì˜ ì†ì‹¤ê³¼ NSP ì˜ˆì¸¡ ì†ì‹¤ì´ ê°ê° êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "pn4zfXPZRG9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜\n",
        "seq_len = 100        # ì…ë ¥ ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´(í† í° ìˆ˜). ëª¨ë“  ë¬¸ì¥ì„ ê¸¸ì´ 100ìœ¼ë¡œ íŒ¨ë”©/ì˜ë¼ëƒ„\n",
        "embed_dim = 128      # ì„ë² ë”© ì°¨ì›: ê° í† í°ì„ 128ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜\n",
        "num_heads = 4        # Multi-Head Attentionì˜ í—¤ë“œ ìˆ˜ (embed_dimì€ head ìˆ˜ë¡œ ë‚˜ëˆ ë–¨ì–´ì ¸ì•¼ í•¨)\n",
        "feed_dim = 256       # FFN(Feed Forward Network) ë‚´ë¶€ í™•ì¥ ì°¨ì› (128 â†’ 256 â†’ 128)\n",
        "num_layers = 4       # Transformer Encoder ë¸”ë¡ ê°œìˆ˜. ê¹Šì´ê°€ ê¹Šì„ìˆ˜ë¡ í‘œí˜„ë ¥ ì¦ê°€\n",
        "num_classes = 2      # ë¶„ë¥˜ í´ë˜ìŠ¤ ìˆ˜(ì˜ˆ: ì´ì§„ ë¶„ë¥˜ = 2)\n",
        "num_epochs = 50      # ì „ì²´ í•™ìŠµ ë°ì´í„°ì…‹ì„ ë°˜ë³µ í•™ìŠµí•  íšŸìˆ˜ (training epochs)\n",
        "batch_size = 64      # í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë¬¸ì¥ ê°œìˆ˜(mini-batch í¬ê¸°)\n",
        "lr = 1e-4            # í•™ìŠµë¥ (Learning Rate). ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ì†ë„ ì¡°ì ˆ\n",
        "\n",
        "# MLM ë³€í™˜ í•¨ìˆ˜ì— ë„£ì–´ì¤„ ìŠ¤í˜ì…œ í† í° ì •ì˜\n",
        "mask_id = sp.get_piece_size()\n",
        "special_tokens_ids = [sp.bos_id(), sp.eos_id(), 0]\n",
        "\n",
        "# ë§ˆìŠ¤í¬ í† í°ì´ ì¶”ê°€ë˜ë¯€ë¡œ í† í°ê°œìˆ˜ì— + 1\n",
        "sp = spm.SentencePieceProcessor(model_file=f'./bpe/spm_krsent.model')\n",
        "vocab_size = sp.get_piece_size() + 1\n",
        "\n",
        "# ë°ì´í„°ì„¸íŠ¸ ë¶„í• \n",
        "dataset = SPDataSet(sp, seq_len)\n",
        "generator1 = torch.Generator().manual_seed(42)\n",
        "test_dataset, train_dataset = random_split(dataset, [0.2, 0.8], generator=generator1)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f'train dataset size: {len(train_dataset)}')\n",
        "print(f'test dataset size: {len(test_dataset)}')\n",
        "\n",
        "# ëª¨ë¸ ìƒì„±\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleBERT(vocab_size, embed_dim, num_heads, feed_dim, num_layers, num_classes).to(device)\n",
        "\n",
        "# 2ê°œì˜ ì†ì‹¤ ìƒì„±\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "mlm_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)        # MLM\n",
        "nsp_loss_fn = nn.CrossEntropyLoss()                         # NSP\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC16JEvtRIgy",
        "outputId": "5a8ebabc-7fc3-47cc-dc95-a1d0964c7344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤.', 'ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ì£¼ìœ„ì— ì˜ë…¼í•  ìƒëŒ€ê°€ ìˆë‚˜ìš”?', 1), ('ì´ë²ˆ ë‹¬ì— ë˜ ê¸‰ì—¬ê°€ ê¹ì˜€ì–´! ë¬¼ê°€ëŠ” ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ë§Œ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ë‚˜.', 'ê¸‰ì—¬ê°€ ì¤„ì–´ ì†ìƒí•˜ì‹œê² ì–´ìš”. ì›”ê¸‰ì´ ì¤„ì–´ë“  ê²ƒì„ ì–´ë–»ê²Œ ë³´ì™„í•˜ì‹¤ ê±´ê°€ìš”?', 1), ('íšŒì‚¬ì— ì‹ ì…ì´ ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ê°€ ê±°ìŠ¬ë ¤. ê·¸ëŸ° ì• ë¥¼ ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê°í•˜ë‹ˆê¹Œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„. ', 'íšŒì‚¬ ë™ë£Œ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ëŠ” ê²ƒ ê°™ì•„ìš”. ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ í•˜ë©´ ì¢‹ì„ê¹Œìš”?', 1), ('ì§ì¥ì—ì„œ ë§‰ë‚´ë¼ëŠ” ì´ìœ ë¡œ ë‚˜ì—ê²Œë§Œ ì˜¨ê°– ì‹¬ë¶€ë¦„ì„ ì‹œì¼œ. ì¼ë„ ë§ì€ ë° ì •ë§ ë¶„í•˜ê³  ì„­ì„­í•´.', 'ê´€ë ¨ ì—†ëŠ” ì‹¬ë¶€ë¦„ì„ ëª¨ë‘ í•˜ê²Œ ë˜ì–´ì„œ ë…¸ì—¬ìš°ì‹œêµ°ìš”. ì–´ë–¤ ê²ƒì´ ìƒí™©ì„ ë‚˜ì•„ì§ˆ ìˆ˜ ìˆê²Œ ë„ì›€ì„ ì¤„ê¹Œìš”?', 1), ('ì–¼ë§ˆ ì „ ì…ì‚¬í•œ ì‹ ì…ì‚¬ì›ì´ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ë‚˜.', 'ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì€ íƒœë„ì— í™”ê°€ ë‚˜ì…¨êµ°ìš”. ìƒëŒ€ë°©ì˜ ì–´ë–¤ í–‰ë™ì´ ê·¸ëŸ° ê°ì •ì„ ìœ ë°œí•˜ëŠ” ê²ƒì¼ê¹Œìš”?', 1), ('ì§ì¥ì— ë‹¤ë‹ˆê³  ìˆì§€ë§Œ ì‹œê°„ë§Œ ë²„ë¦¬ëŠ” ê±° ê°™ì•„. ì§„ì§€í•˜ê²Œ ì§„ë¡œì— ëŒ€í•œ ê³ ë¯¼ì´ ìƒê²¨.', 'ì§„ë¡œì— ëŒ€í•´ì„œ ê³ ë¯¼í•˜ê³  ê³„ì‹œëŠ”êµ°ìš”. ì–´ë–¤ ì ì´ ê³ ë¯¼ì¸ê°€ìš”?', 1), ('ì„±ì¸ì¸ë°ë„ ì§„ë¡œë¥¼ ì•„ì§ë„ ëª» ì •í–ˆë‹¤ê³  ë¶€ëª¨ë‹˜ì´ ë…¸ì—¬ì›Œí•˜ì…”. ë‚˜ë„ ì„­ì„­í•´.', 'ë¶€ëª¨ë‹˜ì˜ ë…¸ì—¬ì›€ì— ì„­ì„­í•˜ì‹œêµ°ìš”. ì´ëŸ° ìƒí™©ì„ ì–´ë–»ê²Œ í•´ê²°í•˜ë©´ ì¢‹ì„ê¹Œìš”? ', 1), ('í‡´ì‚¬í•œ ì§€ ì–¼ë§ˆ ì•ˆ ëì§€ë§Œ ì²œì²œíˆ ì§ì¥ì„ êµ¬í•´ë³´ë ¤ê³ .', 'ì²œì²œíˆë¼ë„ ì§ì¥ì„ êµ¬í•´ ë³´ë ¤ê³  í•˜ì‹œëŠ”êµ°ìš”. íŠ¹ë³„í•œ ì´ìœ ê°€ ìˆìœ¼ì‹ ê°€ìš”?', 1), ('ì¡¸ì—…ë°˜ì´ë¼ì„œ ì·¨ì—…ì„ ìƒê°í•´ì•¼ í•˜ëŠ”ë° ì§€ê¸ˆ ë„ˆë¬´ ëŠê¸‹í•´ì„œ ì´ë˜ë„ ë˜ë‚˜ ì‹¶ì–´.', 'ì·¨ì—…ì— ëŒ€í•´ ê±±ì •ì´ ë˜ëŠ”êµ°ìš”.', 1), ('ìš”ì¦˜ ì§ì¥ìƒí™œì´ ë„ˆë¬´ í¸í•˜ê³  ì¢‹ì€ ê²ƒ ê°™ì•„!', 'ì§ì¥ìƒí™œì´ í¸í•˜ê³  ì¢‹ìœ¼ì‹œë‹¤ë‹ˆ ì¢‹ì•„ ë³´ì—¬ìš”. ë‹¤ë‹ˆê³  ê³„ì‹  íšŒì‚¬ë§Œì˜ ì¥ì ì´ ìˆë‚˜ìš”?', 1)]\n",
            "[('ìš”ì¦˜ ë“¤ì–´ ë¶€ì© ëª¸ì´ ì•ˆ ì¢‹ì•„ì§„ ê±° ê°™ì•„. ì•„ì§ ì• ë“¤ë„ ë‹¤ ì•ˆ ì»¸ëŠ”ë° ê±±ì •ì´ ë¼.', 'í•™êµ ê°€ëŠ”ê²Œ í˜ë“œì‹œêµ°ìš”. ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?', 0), ('ëŠ™ì–´ê°€ëŠ” ê²Œ ëŠê»´ì ¸. ì´ì œ ì¼í•  ë•Œë„ í˜ì´ ë¶€ì¡±í•˜ë‹¨ ê±¸ ëŠê»´ì„œ ì†ìƒí•´.', 'ê°€ì¡±ë“¤ ë•Œë¬¸ì— í™”ê°€ ë§ì´ ë‚¬êµ°ìš”. ë” ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì‹œê² ì–´ìš”?', 0), ('ë‚¨í¸ì´ ë‚´ ê³ì„ ë– ë‚¬ì–´. ì•„ë¬´ê²ƒë„ ëª» í•´ì¤€ ë‚´ê°€ ì‹¤ë§ìŠ¤ëŸ½ê³  ìê¾¸ ëˆˆë¬¼ì´ ë‚˜.', 'ìš”ì¦˜ ì–´ë–¤ ì¼ë“¤ì´ ìˆì—ˆì–´ìš”?', 0), ('ê±´ê°•ê´€ë¦¬ë¥¼ ë„ˆë¬´ ì•ˆ í•´ì„œ ê±´ê°•ì´ ì¢‹ì§€ ì•Šì•„ ì¡Œì–´. ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ í ë¼ì¹ ê¹Œ ë´ ê±±ì •ë¼.', 'ëª¨ë‘ê°€ ìì‹ ì„ í”¼í•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ì™¸ë¡œìš°ì‹œêµ°ìš”.', 0), ('ì´ì œ ëª¸ì´ ì ì  ì•½í•´ì§„ë‹¤ëŠ” ê²Œ ëŠê»´ì ¸. ì•„ë‚´ì—ê²Œ ë¯¸ì•ˆí•˜ê³  ì†ìƒí•œ ë§ˆìŒì´ ë“¤ì–´.', 'ìš”ì¦˜ í˜ë“œì‹œêµ°ìš”. ë‚˜ë¥¼ í˜ë“¤ê²Œ í•œ ì¼ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?', 0), ('ë‚˜ì´ê°€ ë‹¤ ë¼ì„œ í‡´ì§ì„ í•˜ê²Œ ë˜ì—ˆì–´. í•˜ì§€ë§Œ ë…¸í›„ ì¤€ë¹„ë¥¼ ì œëŒ€ë¡œ ì•ˆ í•´ì„œ ëˆ ê±±ì •ì´ ì•ì„œ.', 'í•™êµì—ì„œ í•™êµí­ë ¥ì„ ë‹¹í•˜ê³  ìˆì–´ ë§ì´ ì†ìƒí•˜ì‹œê² ì–´ìš”.', 0), ('ë‚˜ì´ê°€ ë¨¹ê³  ì´ì œ ëˆë„ ëª» ë²Œì–´ ì˜¤ë‹ˆê¹Œ ì–´ë–»ê²Œ ì‚´ì•„ê°€ì•¼ í• ì§€ ë§‰ë§‰í•´. ëŠ¥ë ¥ë„ ì—†ê³ .', 'í•˜ë‚˜ ë¿ì¸ ì¹œêµ¬ê°€ ì²˜ì§€ ë•Œë¬¸ì— ê»„ë„ëŸ½ë‹¤ë‹ˆ ë§ì´ ê³ ë¯¼ë˜ì‹œê² ì–´ìš”.', 0), ('ëª¸ì´ ë§ì´ ì•½í•´ì¡Œë‚˜ ë´. ì´ì œ ì „ê³¼ ê°™ì´ ì¼í•˜ì§€ ëª»í•  ê²ƒ ê°™ì•„ ë„ˆë¬´ ì§œì¦ ë‚˜.', 'í•™êµì—ì„œì˜ ë”°ëŒë¦¼ ë•Œë¬¸ì— ì•½í•´ì§„ë‹¤ê³  ëŠë¼ì‹œëŠ” ê²ƒ ê°™ì•„ìš”.', 0), ('ì´ì œ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´. ë‚¨í¸ë„ ê·¸ë ‡ê³  ë…¸í›„ ì¤€ë¹„ë„ ì•ˆ ë˜ì–´ì„œ ë¯¸ë˜ê°€ ê±±ì •ë¼.', 'ê²°í˜¼ì‹ì— ë¶€ë¥¼ í•˜ê°ì´ ì—†ì–´ì„œ ê±±ì •í•˜ì‹œëŠ”êµ°ìš”.', 0), ('ëª‡ì‹­ ë…„ì„ í•¨ê»˜ ì‚´ì•˜ë˜ ë‚¨í¸ê³¼ ì´í˜¼í–ˆì–´. ê·¸ë™ì•ˆì˜ ì„¸ì›”ì— ë°°ì‹ ê°ì„ ëŠë¼ê³  ë„ˆë¬´ í™”ê°€ ë‚˜.', 'ì—°ê¸ˆ ë•Œë¬¸ì— ë§ì´ ì‹¤ë§í•˜ì‹  ê²ƒ ê°™ì•„ìš”.', 0)]\n",
            "train dataset size: 82602\n",
            "test dataset size: 20651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('./checkpoint'):\n",
        "    os.mkdir('./checkpoint')\n",
        "\n",
        "train_loss = []\n",
        "test_acc = []\n",
        "\n",
        "# í•™ìŠµ\n",
        "for epoch in range(num_epochs):\n",
        "    t_mlm_loss = 0.0\n",
        "    t_nsp_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (inp, labels, mask) in enumerate(train_loader):\n",
        "        inp = inp.long().to(device)\n",
        "        nsp_label = labels.to(device)\n",
        "        mask = mask.to(device)\n",
        "        mlm_inp, mlm_labels = mask_tokens_for_mlm(inp.long(),\n",
        "                                                  special_tokens_ids,\n",
        "                                                  mask_id, vocab_size)\n",
        "        mlm_logits, nsp_logits = model(mlm_inp, mask, mode=\"both\")\n",
        "\n",
        "        # MLM: batch*seq í˜•ìƒ ë³€í™˜í•˜ì—¬ ì†ì‹¤ ê³„ì‚°\n",
        "        mlm_loss = mlm_loss_fn(mlm_logits.view(-1, vocab_size), mlm_labels.view(-1))\n",
        "        mlm_loss = mlm_loss_fn(mlm_logits.view(-1, vocab_size), mlm_labels.view(-1))\n",
        "\n",
        "        # NSP ì†ì‹¤ ê³„ì‚°\n",
        "        nsp_loss = nsp_loss_fn(nsp_logits, nsp_label)\n",
        "\n",
        "        # ë‘ ì†ì‹¤ì„ ë”í•˜ì—¬ ì—­ì „íŒŒ\n",
        "        loss = mlm_loss + nsp_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        t_mlm_loss += mlm_loss.item()\n",
        "        t_nsp_loss += nsp_loss.item()\n",
        "\n",
        "        if (i+1) % 200 == 0:\n",
        "            print(f\"Epoch: {epoch}, Batch: {i+1}, MLM Loss: {t_mlm_loss/(i+1)}, NSP Loss:{t_nsp_loss/(i+1)}\")\n",
        "\n",
        "    avg_loss = (t_mlm_loss + t_nsp_loss) / len(train_loader)\n",
        "    print(f\"Train ===> Epoch {epoch+1} Loss: {avg_loss}\")\n",
        "    train_loss.append(avg_loss)\n",
        "    checkpoint_path = f\"checkpoint/ckpt{epoch}.pt\"\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "    # í‰ê°€ ê³¼ì •(NSP ì •í™•ë„ë§Œ í™•ì¸)\n",
        "    v_acc = 0.0\n",
        "    v_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, labels, mask) in enumerate(val_loader):\n",
        "            inp = inp.long().to(device)\n",
        "            labels = labels.to(device)\n",
        "            mask = mask.to(device)\n",
        "            mlm_logits, nsp_logits = model(inp, mask)\n",
        "\n",
        "            # NSP ì •í™•ë„ ì—°ì‚°\n",
        "            acc = (nsp_logits.argmax(dim=1) == labels).sum() / len(labels)\n",
        "            v_acc += acc\n",
        "\n",
        "        avg_acc = v_acc / len(val_loader)\n",
        "        print(f\"Val ---> Epoch {epoch+1}, Val_NSP_Accuracy: {avg_acc}\")\n",
        "        test_acc.append(avg_acc.cpu().numpy())\n",
        "\n",
        "    print(\"-\"*30)\n",
        "\n",
        "torch.save(model, \"model1.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "25B9j1gWRyya",
        "outputId": "e97d7f6d-4148-458a-e981-a62c55e29cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 200, MLM Loss: 7.249395792484283, NSP Loss:0.7023992416262627\n",
            "Epoch: 0, Batch: 400, MLM Loss: 6.872677938938141, NSP Loss:0.6990194888412953\n",
            "Epoch: 0, Batch: 600, MLM Loss: 6.720965439478556, NSP Loss:0.6981598915656407\n",
            "Epoch: 0, Batch: 800, MLM Loss: 6.6282850360870365, NSP Loss:0.6979846480488777\n",
            "Epoch: 0, Batch: 1000, MLM Loss: 6.5651493401527405, NSP Loss:0.6978199633955956\n",
            "Epoch: 0, Batch: 1200, MLM Loss: 6.518931322892507, NSP Loss:0.6975448261698087\n",
            "Train ===> Epoch 1 Loss: 7.198780322518116\n",
            "Val ---> Epoch 1, Val_NSP_Accuracy: 0.5390473008155823\n",
            "------------------------------\n",
            "Epoch: 1, Batch: 200, MLM Loss: 6.273930330276489, NSP Loss:0.6939492490887642\n",
            "Epoch: 1, Batch: 400, MLM Loss: 6.253475111722946, NSP Loss:0.6949601590633392\n",
            "Epoch: 1, Batch: 600, MLM Loss: 6.243500349521637, NSP Loss:0.6947070940335591\n",
            "Epoch: 1, Batch: 800, MLM Loss: 6.234648743271828, NSP Loss:0.6949160896986722\n",
            "Epoch: 1, Batch: 1000, MLM Loss: 6.228800703525543, NSP Loss:0.6948873289227485\n",
            "Epoch: 1, Batch: 1200, MLM Loss: 6.220771245161692, NSP Loss:0.6946850542724132\n",
            "Train ===> Epoch 2 Loss: 6.911706632417269\n",
            "Val ---> Epoch 2, Val_NSP_Accuracy: 0.5319620966911316\n",
            "------------------------------\n",
            "Epoch: 2, Batch: 200, MLM Loss: 6.152431817054748, NSP Loss:0.6925766572356225\n",
            "Epoch: 2, Batch: 400, MLM Loss: 6.153449840545655, NSP Loss:0.6930832622945309\n",
            "Epoch: 2, Batch: 600, MLM Loss: 6.140704131921132, NSP Loss:0.6930502462387085\n",
            "Epoch: 2, Batch: 800, MLM Loss: 6.133606671094895, NSP Loss:0.6925160143524408\n",
            "Epoch: 2, Batch: 1000, MLM Loss: 6.126303829669952, NSP Loss:0.6927044318318367\n",
            "Epoch: 2, Batch: 1200, MLM Loss: 6.121690665880839, NSP Loss:0.6927057682474455\n",
            "Train ===> Epoch 3 Loss: 6.812053834994942\n",
            "Val ---> Epoch 3, Val_NSP_Accuracy: 0.5263506174087524\n",
            "------------------------------\n",
            "Epoch: 3, Batch: 200, MLM Loss: 6.067269635200501, NSP Loss:0.6911965906620026\n",
            "Epoch: 3, Batch: 400, MLM Loss: 6.069202123880387, NSP Loss:0.6904654365777969\n",
            "Epoch: 3, Batch: 600, MLM Loss: 6.066938291390737, NSP Loss:0.690510448316733\n",
            "Epoch: 3, Batch: 800, MLM Loss: 6.054060871005058, NSP Loss:0.6909417272359133\n",
            "Epoch: 3, Batch: 1000, MLM Loss: 6.047745866298675, NSP Loss:0.690881622493267\n",
            "Epoch: 3, Batch: 1200, MLM Loss: 6.044815346399943, NSP Loss:0.69037426268061\n",
            "Train ===> Epoch 4 Loss: 6.733550158837892\n",
            "Val ---> Epoch 4, Val_NSP_Accuracy: 0.5471967458724976\n",
            "------------------------------\n",
            "Epoch: 4, Batch: 200, MLM Loss: 5.987510154247284, NSP Loss:0.6872023743391037\n",
            "Epoch: 4, Batch: 400, MLM Loss: 5.986019389629364, NSP Loss:0.6878720346093178\n",
            "Epoch: 4, Batch: 600, MLM Loss: 5.986403326193492, NSP Loss:0.6880292856693268\n",
            "Epoch: 4, Batch: 800, MLM Loss: 5.976103354096413, NSP Loss:0.6874492113292218\n",
            "Epoch: 4, Batch: 1000, MLM Loss: 5.973580310344696, NSP Loss:0.6871818696260452\n",
            "Epoch: 4, Batch: 1200, MLM Loss: 5.9680513123671215, NSP Loss:0.6870464337368806\n",
            "Train ===> Epoch 5 Loss: 6.653311354351265\n",
            "Val ---> Epoch 5, Val_NSP_Accuracy: 0.5329768061637878\n",
            "------------------------------\n",
            "Epoch: 5, Batch: 200, MLM Loss: 5.9333903908729555, NSP Loss:0.6860551846027374\n",
            "Epoch: 5, Batch: 400, MLM Loss: 5.930409742593765, NSP Loss:0.6852200962603092\n",
            "Epoch: 5, Batch: 600, MLM Loss: 5.918441321849823, NSP Loss:0.6860458409786224\n",
            "Epoch: 5, Batch: 800, MLM Loss: 5.9104620444774625, NSP Loss:0.6856968614459038\n",
            "Epoch: 5, Batch: 1000, MLM Loss: 5.905893767833709, NSP Loss:0.6854759129285812\n",
            "Epoch: 5, Batch: 1200, MLM Loss: 5.901011645793915, NSP Loss:0.6854970006644726\n",
            "Train ===> Epoch 6 Loss: 6.584350444474579\n",
            "Val ---> Epoch 6, Val_NSP_Accuracy: 0.5528115630149841\n",
            "------------------------------\n",
            "Epoch: 6, Batch: 200, MLM Loss: 5.8611540961265565, NSP Loss:0.6849628233909607\n",
            "Epoch: 6, Batch: 400, MLM Loss: 5.8562890458106995, NSP Loss:0.6847940529882908\n",
            "Epoch: 6, Batch: 600, MLM Loss: 5.848513004779815, NSP Loss:0.6837772434949875\n",
            "Epoch: 6, Batch: 800, MLM Loss: 5.839183085560799, NSP Loss:0.6835576721280813\n",
            "Epoch: 6, Batch: 1000, MLM Loss: 5.835697838783264, NSP Loss:0.6828565675616264\n",
            "Epoch: 6, Batch: 1200, MLM Loss: 5.834681816895803, NSP Loss:0.6826601712902387\n",
            "Train ===> Epoch 7 Loss: 6.513885525194459\n",
            "Val ---> Epoch 7, Val_NSP_Accuracy: 0.5417337417602539\n",
            "------------------------------\n",
            "Epoch: 7, Batch: 200, MLM Loss: 5.790535128116607, NSP Loss:0.6808048039674759\n",
            "Epoch: 7, Batch: 400, MLM Loss: 5.784383324384689, NSP Loss:0.6796596609055996\n",
            "Epoch: 7, Batch: 600, MLM Loss: 5.782487257321676, NSP Loss:0.6810523681839307\n",
            "Epoch: 7, Batch: 800, MLM Loss: 5.78113509118557, NSP Loss:0.6803965292125941\n",
            "Epoch: 7, Batch: 1000, MLM Loss: 5.780922278881073, NSP Loss:0.6800402165055275\n",
            "Epoch: 7, Batch: 1200, MLM Loss: 5.77919061978658, NSP Loss:0.6796608918905258\n",
            "Train ===> Epoch 8 Loss: 6.456483148863665\n",
            "Val ---> Epoch 8, Val_NSP_Accuracy: 0.553051233291626\n",
            "------------------------------\n",
            "Epoch: 8, Batch: 200, MLM Loss: 5.73781126499176, NSP Loss:0.6763131669163704\n",
            "Epoch: 8, Batch: 400, MLM Loss: 5.744145741462708, NSP Loss:0.6772176016867161\n",
            "Epoch: 8, Batch: 600, MLM Loss: 5.736196843783061, NSP Loss:0.6772785599033038\n",
            "Epoch: 8, Batch: 800, MLM Loss: 5.73321768283844, NSP Loss:0.6767519671469927\n",
            "Epoch: 8, Batch: 1000, MLM Loss: 5.730301263332367, NSP Loss:0.6765945942997933\n",
            "Epoch: 8, Batch: 1200, MLM Loss: 5.727148263851801, NSP Loss:0.6765232601761818\n",
            "Train ===> Epoch 9 Loss: 6.402176888759149\n",
            "Val ---> Epoch 9, Val_NSP_Accuracy: 0.5637667179107666\n",
            "------------------------------\n",
            "Epoch: 9, Batch: 200, MLM Loss: 5.687374651432037, NSP Loss:0.674942789375782\n",
            "Epoch: 9, Batch: 400, MLM Loss: 5.68590726017952, NSP Loss:0.675958540737629\n",
            "Epoch: 9, Batch: 600, MLM Loss: 5.685324016412099, NSP Loss:0.6752784537275632\n",
            "Epoch: 9, Batch: 800, MLM Loss: 5.6817256653308865, NSP Loss:0.6745578452199698\n",
            "Epoch: 9, Batch: 1000, MLM Loss: 5.679252268791199, NSP Loss:0.6744421706199646\n",
            "Epoch: 9, Batch: 1200, MLM Loss: 5.678100277980168, NSP Loss:0.674446181555589\n",
            "Train ===> Epoch 10 Loss: 6.351049647785544\n",
            "Val ---> Epoch 10, Val_NSP_Accuracy: 0.57017582654953\n",
            "------------------------------\n",
            "Epoch: 10, Batch: 200, MLM Loss: 5.653812010288238, NSP Loss:0.6703089365363121\n",
            "Epoch: 10, Batch: 400, MLM Loss: 5.655301347970963, NSP Loss:0.6716814434528351\n",
            "Epoch: 10, Batch: 600, MLM Loss: 5.652917351722717, NSP Loss:0.6709900092085203\n",
            "Epoch: 10, Batch: 800, MLM Loss: 5.651233441829682, NSP Loss:0.6710869132727385\n",
            "Epoch: 10, Batch: 1000, MLM Loss: 5.649263868331909, NSP Loss:0.6709204755425453\n",
            "Epoch: 10, Batch: 1200, MLM Loss: 5.6456918589274085, NSP Loss:0.6705589240292708\n",
            "Train ===> Epoch 11 Loss: 6.311655596233356\n",
            "Val ---> Epoch 11, Val_NSP_Accuracy: 0.591461718082428\n",
            "------------------------------\n",
            "Epoch: 11, Batch: 200, MLM Loss: 5.614658129215241, NSP Loss:0.6667716115713119\n",
            "Epoch: 11, Batch: 400, MLM Loss: 5.616509040594101, NSP Loss:0.6679644595086575\n",
            "Epoch: 11, Batch: 600, MLM Loss: 5.613393920262655, NSP Loss:0.6679691894849141\n",
            "Epoch: 11, Batch: 800, MLM Loss: 5.606913457512856, NSP Loss:0.6672727493196726\n",
            "Epoch: 11, Batch: 1000, MLM Loss: 5.602447868347168, NSP Loss:0.6666730261445045\n",
            "Epoch: 11, Batch: 1200, MLM Loss: 5.600466831525167, NSP Loss:0.6666195976237456\n",
            "Train ===> Epoch 12 Loss: 6.266546794742138\n",
            "Val ---> Epoch 12, Val_NSP_Accuracy: 0.6166154146194458\n",
            "------------------------------\n",
            "Epoch: 12, Batch: 200, MLM Loss: 5.5802219152450565, NSP Loss:0.6648551419377327\n",
            "Epoch: 12, Batch: 400, MLM Loss: 5.572157869338989, NSP Loss:0.6637870813906193\n",
            "Epoch: 12, Batch: 600, MLM Loss: 5.574526515007019, NSP Loss:0.6641672641038895\n",
            "Epoch: 12, Batch: 800, MLM Loss: 5.57450269639492, NSP Loss:0.6641001468151808\n",
            "Epoch: 12, Batch: 1000, MLM Loss: 5.574315806388855, NSP Loss:0.6635956129431725\n",
            "Epoch: 12, Batch: 1200, MLM Loss: 5.573403143485387, NSP Loss:0.6631899923582871\n",
            "Train ===> Epoch 13 Loss: 6.235915674062592\n",
            "Val ---> Epoch 13, Val_NSP_Accuracy: 0.6142709255218506\n",
            "------------------------------\n",
            "Epoch: 13, Batch: 200, MLM Loss: 5.549479067325592, NSP Loss:0.6622581920027732\n",
            "Epoch: 13, Batch: 400, MLM Loss: 5.543290522098541, NSP Loss:0.66278627961874\n",
            "Epoch: 13, Batch: 600, MLM Loss: 5.546210538546244, NSP Loss:0.6610638785362244\n",
            "Epoch: 13, Batch: 800, MLM Loss: 5.5406114012002945, NSP Loss:0.660810509622097\n",
            "Epoch: 13, Batch: 1000, MLM Loss: 5.538256810188294, NSP Loss:0.6612271683216095\n",
            "Epoch: 13, Batch: 1200, MLM Loss: 5.538885285059611, NSP Loss:0.660424025307099\n",
            "Train ===> Epoch 14 Loss: 6.199146782631656\n",
            "Val ---> Epoch 14, Val_NSP_Accuracy: 0.6309106945991516\n",
            "------------------------------\n",
            "Epoch: 14, Batch: 200, MLM Loss: 5.51223326921463, NSP Loss:0.6557834905385971\n",
            "Epoch: 14, Batch: 400, MLM Loss: 5.510343225002289, NSP Loss:0.6570314389467239\n",
            "Epoch: 14, Batch: 600, MLM Loss: 5.514553059736888, NSP Loss:0.6580819379289945\n",
            "Epoch: 14, Batch: 800, MLM Loss: 5.5113052374124525, NSP Loss:0.6574554296582937\n",
            "Epoch: 14, Batch: 1000, MLM Loss: 5.5102521276474, NSP Loss:0.6579595437049865\n",
            "Epoch: 14, Batch: 1200, MLM Loss: 5.507717787822088, NSP Loss:0.6576775015890598\n",
            "Train ===> Epoch 15 Loss: 6.163224345025491\n",
            "Val ---> Epoch 15, Val_NSP_Accuracy: 0.6278383731842041\n",
            "------------------------------\n",
            "Epoch: 15, Batch: 200, MLM Loss: 5.479338550567627, NSP Loss:0.65378374427557\n",
            "Epoch: 15, Batch: 400, MLM Loss: 5.480240907669067, NSP Loss:0.653884041160345\n",
            "Epoch: 15, Batch: 600, MLM Loss: 5.489151182174683, NSP Loss:0.6528664255142211\n",
            "Epoch: 15, Batch: 800, MLM Loss: 5.485723537802696, NSP Loss:0.6529825992137194\n",
            "Epoch: 15, Batch: 1000, MLM Loss: 5.482183707714081, NSP Loss:0.6531402074098587\n",
            "Epoch: 15, Batch: 1200, MLM Loss: 5.4806232865651445, NSP Loss:0.6529735984404882\n",
            "Train ===> Epoch 16 Loss: 6.134230915379099\n",
            "Val ---> Epoch 16, Val_NSP_Accuracy: 0.6233170032501221\n",
            "------------------------------\n",
            "Epoch: 16, Batch: 200, MLM Loss: 5.47421345949173, NSP Loss:0.649600892663002\n",
            "Epoch: 16, Batch: 400, MLM Loss: 5.472827882766723, NSP Loss:0.649219891577959\n",
            "Epoch: 16, Batch: 600, MLM Loss: 5.468258008162181, NSP Loss:0.6482868308822314\n",
            "Epoch: 16, Batch: 800, MLM Loss: 5.465740562081337, NSP Loss:0.6483790248632431\n",
            "Epoch: 16, Batch: 1000, MLM Loss: 5.4640397191047665, NSP Loss:0.648269332587719\n",
            "Epoch: 16, Batch: 1200, MLM Loss: 5.4608896338939665, NSP Loss:0.648856267730395\n",
            "Train ===> Epoch 17 Loss: 6.1083197492116375\n",
            "Val ---> Epoch 17, Val_NSP_Accuracy: 0.6201726198196411\n",
            "------------------------------\n",
            "Epoch: 17, Batch: 200, MLM Loss: 5.448104674816132, NSP Loss:0.6505801838636398\n",
            "Epoch: 17, Batch: 400, MLM Loss: 5.440696386098861, NSP Loss:0.6486099055409431\n",
            "Epoch: 17, Batch: 600, MLM Loss: 5.440019801457723, NSP Loss:0.6488384214043618\n",
            "Epoch: 17, Batch: 800, MLM Loss: 5.436564689874649, NSP Loss:0.6487289217114448\n",
            "Epoch: 17, Batch: 1000, MLM Loss: 5.434337713241577, NSP Loss:0.6488518142104149\n",
            "Epoch: 17, Batch: 1200, MLM Loss: 5.4359858206907905, NSP Loss:0.6477578423420588\n",
            "Train ===> Epoch 18 Loss: 6.084343230511956\n",
            "Val ---> Epoch 18, Val_NSP_Accuracy: 0.6236792206764221\n",
            "------------------------------\n",
            "Epoch: 18, Batch: 200, MLM Loss: 5.422330985069275, NSP Loss:0.643448635339737\n",
            "Epoch: 18, Batch: 400, MLM Loss: 5.425989588499069, NSP Loss:0.6446129257977009\n",
            "Epoch: 18, Batch: 600, MLM Loss: 5.430840631326039, NSP Loss:0.6447899576028188\n",
            "Epoch: 18, Batch: 800, MLM Loss: 5.42562403857708, NSP Loss:0.6446366822719574\n",
            "Epoch: 18, Batch: 1000, MLM Loss: 5.4253780789375305, NSP Loss:0.6449298980236053\n",
            "Epoch: 18, Batch: 1200, MLM Loss: 5.423069038788477, NSP Loss:0.644517627308766\n",
            "Train ===> Epoch 19 Loss: 6.067442931933148\n",
            "Val ---> Epoch 19, Val_NSP_Accuracy: 0.6126487255096436\n",
            "------------------------------\n",
            "Epoch: 19, Batch: 200, MLM Loss: 5.416017513275147, NSP Loss:0.6364918375015258\n",
            "Epoch: 19, Batch: 400, MLM Loss: 5.4013887214660645, NSP Loss:0.6387154369056225\n",
            "Epoch: 19, Batch: 600, MLM Loss: 5.3981414937973025, NSP Loss:0.6393473582466443\n",
            "Epoch: 19, Batch: 800, MLM Loss: 5.394959680438042, NSP Loss:0.6396315528452396\n",
            "Epoch: 19, Batch: 1000, MLM Loss: 5.394475628376007, NSP Loss:0.639857429087162\n",
            "Epoch: 19, Batch: 1200, MLM Loss: 5.3936405336856845, NSP Loss:0.6406594814856847\n",
            "Train ===> Epoch 20 Loss: 6.035113184189815\n",
            "Val ---> Epoch 20, Val_NSP_Accuracy: 0.6307418942451477\n",
            "------------------------------\n",
            "Epoch: 20, Batch: 200, MLM Loss: 5.405762462615967, NSP Loss:0.6389803010225296\n",
            "Epoch: 20, Batch: 400, MLM Loss: 5.39579415678978, NSP Loss:0.6366827873885632\n",
            "Epoch: 20, Batch: 600, MLM Loss: 5.389390165011088, NSP Loss:0.6374060595035553\n",
            "Epoch: 20, Batch: 800, MLM Loss: 5.3859508609771725, NSP Loss:0.6374076988548041\n",
            "Epoch: 20, Batch: 1000, MLM Loss: 5.383381174564361, NSP Loss:0.6376360331773758\n",
            "Epoch: 20, Batch: 1200, MLM Loss: 5.3866742821534475, NSP Loss:0.637634492913882\n",
            "Train ===> Epoch 21 Loss: 6.022359372247198\n",
            "Val ---> Epoch 21, Val_NSP_Accuracy: 0.64980149269104\n",
            "------------------------------\n",
            "Epoch: 21, Batch: 200, MLM Loss: 5.362429065704346, NSP Loss:0.6339184817671776\n",
            "Epoch: 21, Batch: 400, MLM Loss: 5.361941342353821, NSP Loss:0.6351916669309139\n",
            "Epoch: 21, Batch: 600, MLM Loss: 5.361436948776245, NSP Loss:0.6343049296736717\n",
            "Epoch: 21, Batch: 800, MLM Loss: 5.359052747488022, NSP Loss:0.6339933063089848\n",
            "Epoch: 21, Batch: 1000, MLM Loss: 5.358964864730835, NSP Loss:0.6339243839979172\n",
            "Epoch: 21, Batch: 1200, MLM Loss: 5.359346253871918, NSP Loss:0.6339044476548831\n",
            "Train ===> Epoch 22 Loss: 5.993774052741083\n",
            "Val ---> Epoch 22, Val_NSP_Accuracy: 0.6498488187789917\n",
            "------------------------------\n",
            "Epoch: 22, Batch: 200, MLM Loss: 5.341833488941193, NSP Loss:0.6295297262072563\n",
            "Epoch: 22, Batch: 400, MLM Loss: 5.343849023580551, NSP Loss:0.6324876204133034\n",
            "Epoch: 22, Batch: 600, MLM Loss: 5.351974606513977, NSP Loss:0.6319715876877308\n",
            "Epoch: 22, Batch: 800, MLM Loss: 5.349246286153793, NSP Loss:0.6313925234600901\n",
            "Epoch: 22, Batch: 1000, MLM Loss: 5.344274869918824, NSP Loss:0.6308612701594829\n",
            "Epoch: 22, Batch: 1200, MLM Loss: 5.343452307383219, NSP Loss:0.6317497971405586\n",
            "Train ===> Epoch 23 Loss: 5.97561501480183\n",
            "Val ---> Epoch 23, Val_NSP_Accuracy: 0.6620144248008728\n",
            "------------------------------\n",
            "Epoch: 23, Batch: 200, MLM Loss: 5.327037584781647, NSP Loss:0.6291534787416458\n",
            "Epoch: 23, Batch: 400, MLM Loss: 5.326119440793991, NSP Loss:0.6282287059724331\n",
            "Epoch: 23, Batch: 600, MLM Loss: 5.331752576033274, NSP Loss:0.6275780015190442\n",
            "Epoch: 23, Batch: 800, MLM Loss: 5.332813791632653, NSP Loss:0.6284959165006876\n",
            "Epoch: 23, Batch: 1000, MLM Loss: 5.33596649312973, NSP Loss:0.628031041443348\n",
            "Epoch: 23, Batch: 1200, MLM Loss: 5.331805925766627, NSP Loss:0.6285216652353605\n",
            "Train ===> Epoch 24 Loss: 5.959175879968219\n",
            "Val ---> Epoch 24, Val_NSP_Accuracy: 0.6603213548660278\n",
            "------------------------------\n",
            "Epoch: 24, Batch: 200, MLM Loss: 5.318509151935578, NSP Loss:0.6231211799383164\n",
            "Epoch: 24, Batch: 400, MLM Loss: 5.32906222820282, NSP Loss:0.6261914351582527\n",
            "Epoch: 24, Batch: 600, MLM Loss: 5.323183829784393, NSP Loss:0.6249239140748978\n",
            "Epoch: 24, Batch: 800, MLM Loss: 5.323071746230125, NSP Loss:0.625204268321395\n",
            "Epoch: 24, Batch: 1000, MLM Loss: 5.3156760177612306, NSP Loss:0.6251683294177055\n",
            "Epoch: 24, Batch: 1200, MLM Loss: 5.315090740919113, NSP Loss:0.6263749306400617\n",
            "Train ===> Epoch 25 Loss: 5.939174408233046\n",
            "Val ---> Epoch 25, Val_NSP_Accuracy: 0.6360867619514465\n",
            "------------------------------\n",
            "Epoch: 25, Batch: 200, MLM Loss: 5.31148353099823, NSP Loss:0.6242870602011681\n",
            "Epoch: 25, Batch: 400, MLM Loss: 5.306453082561493, NSP Loss:0.6210889261960983\n",
            "Epoch: 25, Batch: 600, MLM Loss: 5.31050411939621, NSP Loss:0.622073406179746\n",
            "Epoch: 25, Batch: 800, MLM Loss: 5.3107815390825275, NSP Loss:0.6227934791892767\n",
            "Epoch: 25, Batch: 1000, MLM Loss: 5.306329005241394, NSP Loss:0.6218444598913193\n",
            "Epoch: 25, Batch: 1200, MLM Loss: 5.304704364935557, NSP Loss:0.6218601628144582\n",
            "Train ===> Epoch 26 Loss: 5.925445432306536\n",
            "Val ---> Epoch 26, Val_NSP_Accuracy: 0.6633216738700867\n",
            "------------------------------\n",
            "Epoch: 26, Batch: 200, MLM Loss: 5.3166006731987, NSP Loss:0.6133129255473614\n",
            "Epoch: 26, Batch: 400, MLM Loss: 5.310800544023514, NSP Loss:0.6170343164354563\n",
            "Epoch: 26, Batch: 600, MLM Loss: 5.30502692937851, NSP Loss:0.6184718630214532\n",
            "Epoch: 26, Batch: 800, MLM Loss: 5.305801101922989, NSP Loss:0.6192223178967834\n",
            "Epoch: 26, Batch: 1000, MLM Loss: 5.29757726764679, NSP Loss:0.6186910632550716\n",
            "Epoch: 26, Batch: 1200, MLM Loss: 5.294497826099396, NSP Loss:0.6185752422859271\n",
            "Train ===> Epoch 27 Loss: 5.910578750460578\n",
            "Val ---> Epoch 27, Val_NSP_Accuracy: 0.6565728783607483\n",
            "------------------------------\n",
            "Epoch: 27, Batch: 200, MLM Loss: 5.282479493618012, NSP Loss:0.6181767518818378\n",
            "Epoch: 27, Batch: 400, MLM Loss: 5.280180048942566, NSP Loss:0.6189911431074142\n",
            "Epoch: 27, Batch: 600, MLM Loss: 5.277224036852519, NSP Loss:0.6182914646963279\n",
            "Epoch: 27, Batch: 800, MLM Loss: 5.279563006162643, NSP Loss:0.6175947048142553\n",
            "Epoch: 27, Batch: 1000, MLM Loss: 5.277174170970917, NSP Loss:0.6182877030670643\n",
            "Epoch: 27, Batch: 1200, MLM Loss: 5.278595305681229, NSP Loss:0.6180801429102818\n",
            "Train ===> Epoch 28 Loss: 5.898027608161006\n",
            "Val ---> Epoch 28, Val_NSP_Accuracy: 0.6656683683395386\n",
            "------------------------------\n",
            "Epoch: 28, Batch: 200, MLM Loss: 5.256753294467926, NSP Loss:0.6170128628611564\n",
            "Epoch: 28, Batch: 400, MLM Loss: 5.252922216653824, NSP Loss:0.613369263112545\n",
            "Epoch: 28, Batch: 600, MLM Loss: 5.255621821085612, NSP Loss:0.6149936965107918\n",
            "Epoch: 28, Batch: 800, MLM Loss: 5.264489897489548, NSP Loss:0.6147485666722059\n",
            "Epoch: 28, Batch: 1000, MLM Loss: 5.26449026966095, NSP Loss:0.615495109885931\n",
            "Epoch: 28, Batch: 1200, MLM Loss: 5.264464036226273, NSP Loss:0.6146856930106879\n",
            "Train ===> Epoch 29 Loss: 5.878436807303536\n",
            "Val ---> Epoch 29, Val_NSP_Accuracy: 0.6844850182533264\n",
            "------------------------------\n",
            "Epoch: 29, Batch: 200, MLM Loss: 5.269663000106812, NSP Loss:0.6078426297008991\n",
            "Epoch: 29, Batch: 400, MLM Loss: 5.262646722793579, NSP Loss:0.6087647479027509\n",
            "Epoch: 29, Batch: 600, MLM Loss: 5.267149522304535, NSP Loss:0.6100397308170795\n",
            "Epoch: 29, Batch: 800, MLM Loss: 5.2590751194953915, NSP Loss:0.6111130461469293\n",
            "Epoch: 29, Batch: 1000, MLM Loss: 5.258821634292603, NSP Loss:0.6123453790843487\n",
            "Epoch: 29, Batch: 1200, MLM Loss: 5.259047577381134, NSP Loss:0.6122104089210431\n",
            "Train ===> Epoch 30 Loss: 5.872808930003116\n",
            "Val ---> Epoch 30, Val_NSP_Accuracy: 0.6823104023933411\n",
            "------------------------------\n",
            "Epoch: 30, Batch: 200, MLM Loss: 5.232311375141144, NSP Loss:0.6039279061555862\n",
            "Epoch: 30, Batch: 400, MLM Loss: 5.232258793115616, NSP Loss:0.6052972577512264\n",
            "Epoch: 30, Batch: 600, MLM Loss: 5.237810254096985, NSP Loss:0.6051550654073556\n",
            "Epoch: 30, Batch: 800, MLM Loss: 5.243546142578125, NSP Loss:0.6062255987524986\n",
            "Epoch: 30, Batch: 1000, MLM Loss: 5.2443209986686705, NSP Loss:0.6063342262506485\n",
            "Epoch: 30, Batch: 1200, MLM Loss: 5.244909479220708, NSP Loss:0.6068307748436927\n",
            "Train ===> Epoch 31 Loss: 5.850709562565725\n",
            "Val ---> Epoch 31, Val_NSP_Accuracy: 0.6738898754119873\n",
            "------------------------------\n",
            "Epoch: 31, Batch: 200, MLM Loss: 5.230646255016327, NSP Loss:0.6028339123725891\n",
            "Epoch: 31, Batch: 400, MLM Loss: 5.242823178768158, NSP Loss:0.6008436134457589\n",
            "Epoch: 31, Batch: 600, MLM Loss: 5.238971575101217, NSP Loss:0.6039819276332855\n",
            "Epoch: 31, Batch: 800, MLM Loss: 5.239648650884629, NSP Loss:0.6031509565934539\n",
            "Epoch: 31, Batch: 1000, MLM Loss: 5.235729852676392, NSP Loss:0.6046110115647316\n",
            "Epoch: 31, Batch: 1200, MLM Loss: 5.232443937063217, NSP Loss:0.6036410085856915\n",
            "Train ===> Epoch 32 Loss: 5.834104790464101\n",
            "Val ---> Epoch 32, Val_NSP_Accuracy: 0.6861545443534851\n",
            "------------------------------\n",
            "Epoch: 32, Batch: 200, MLM Loss: 5.207189214229584, NSP Loss:0.5976247023046016\n",
            "Epoch: 32, Batch: 400, MLM Loss: 5.225366487503051, NSP Loss:0.6012565425783396\n",
            "Epoch: 32, Batch: 600, MLM Loss: 5.222413047949473, NSP Loss:0.6022307457526525\n",
            "Epoch: 32, Batch: 800, MLM Loss: 5.222249196767807, NSP Loss:0.6030732689797879\n",
            "Epoch: 32, Batch: 1000, MLM Loss: 5.219896051883698, NSP Loss:0.6028308914899826\n",
            "Epoch: 32, Batch: 1200, MLM Loss: 5.219511694113414, NSP Loss:0.602859448765715\n",
            "Train ===> Epoch 33 Loss: 5.822952214573632\n",
            "Val ---> Epoch 33, Val_NSP_Accuracy: 0.6900008320808411\n",
            "------------------------------\n",
            "Epoch: 33, Batch: 200, MLM Loss: 5.195012941360473, NSP Loss:0.5954621835052967\n",
            "Epoch: 33, Batch: 400, MLM Loss: 5.205050339698792, NSP Loss:0.5958456850796938\n",
            "Epoch: 33, Batch: 600, MLM Loss: 5.208179253737132, NSP Loss:0.5939516524473826\n",
            "Epoch: 33, Batch: 800, MLM Loss: 5.210283694267273, NSP Loss:0.5955516426265239\n",
            "Epoch: 33, Batch: 1000, MLM Loss: 5.212292068481445, NSP Loss:0.595912995070219\n",
            "Epoch: 33, Batch: 1200, MLM Loss: 5.2116531809171045, NSP Loss:0.5975390881548325\n",
            "Train ===> Epoch 34 Loss: 5.8086170360480605\n",
            "Val ---> Epoch 34, Val_NSP_Accuracy: 0.6838325262069702\n",
            "------------------------------\n",
            "Epoch: 34, Batch: 200, MLM Loss: 5.2107274532318115, NSP Loss:0.5966698275506497\n",
            "Epoch: 34, Batch: 400, MLM Loss: 5.1953320467472075, NSP Loss:0.5966854056715966\n",
            "Epoch: 34, Batch: 600, MLM Loss: 5.195238255659739, NSP Loss:0.5967703141768773\n",
            "Epoch: 34, Batch: 800, MLM Loss: 5.19739102602005, NSP Loss:0.5964380219206213\n",
            "Epoch: 34, Batch: 1000, MLM Loss: 5.19442146062851, NSP Loss:0.5968193848729133\n",
            "Epoch: 34, Batch: 1200, MLM Loss: 5.194539772669474, NSP Loss:0.5964912141114473\n",
            "Train ===> Epoch 35 Loss: 5.789107225783383\n",
            "Val ---> Epoch 35, Val_NSP_Accuracy: 0.6775201559066772\n",
            "------------------------------\n",
            "Epoch: 35, Batch: 200, MLM Loss: 5.199518139362335, NSP Loss:0.5955385002493858\n",
            "Epoch: 35, Batch: 400, MLM Loss: 5.196802537441254, NSP Loss:0.592008780837059\n",
            "Epoch: 35, Batch: 600, MLM Loss: 5.198723707199097, NSP Loss:0.5903449259201685\n",
            "Epoch: 35, Batch: 800, MLM Loss: 5.189713807106018, NSP Loss:0.5927082078158855\n",
            "Epoch: 35, Batch: 1000, MLM Loss: 5.185009374141693, NSP Loss:0.5930980969965458\n",
            "Epoch: 35, Batch: 1200, MLM Loss: 5.18578442533811, NSP Loss:0.5929451811561982\n",
            "Train ===> Epoch 36 Loss: 5.778180507728058\n",
            "Val ---> Epoch 36, Val_NSP_Accuracy: 0.6484223008155823\n",
            "------------------------------\n",
            "Epoch: 36, Batch: 200, MLM Loss: 5.159082078933716, NSP Loss:0.5880928505957127\n",
            "Epoch: 36, Batch: 400, MLM Loss: 5.174032089710235, NSP Loss:0.5890242787450553\n",
            "Epoch: 36, Batch: 600, MLM Loss: 5.1740465203921, NSP Loss:0.5889220168193181\n",
            "Epoch: 36, Batch: 800, MLM Loss: 5.172562938928604, NSP Loss:0.5886586755514145\n",
            "Epoch: 36, Batch: 1000, MLM Loss: 5.174832272052765, NSP Loss:0.5895707861185074\n",
            "Epoch: 36, Batch: 1200, MLM Loss: 5.175933679739634, NSP Loss:0.5893938805907964\n",
            "Train ===> Epoch 37 Loss: 5.766643918017654\n",
            "Val ---> Epoch 37, Val_NSP_Accuracy: 0.6987318992614746\n",
            "------------------------------\n",
            "Epoch: 37, Batch: 200, MLM Loss: 5.163928842544555, NSP Loss:0.5836542151868344\n",
            "Epoch: 37, Batch: 400, MLM Loss: 5.166175367832184, NSP Loss:0.5854850771278143\n",
            "Epoch: 37, Batch: 600, MLM Loss: 5.1720259308815, NSP Loss:0.585726226568222\n",
            "Epoch: 37, Batch: 800, MLM Loss: 5.166182204484939, NSP Loss:0.586111888103187\n",
            "Epoch: 37, Batch: 1000, MLM Loss: 5.167978506088257, NSP Loss:0.5867137059271336\n",
            "Epoch: 37, Batch: 1200, MLM Loss: 5.165774717728297, NSP Loss:0.5868039709081252\n",
            "Train ===> Epoch 38 Loss: 5.753760469804708\n",
            "Val ---> Epoch 38, Val_NSP_Accuracy: 0.6993843913078308\n",
            "------------------------------\n",
            "Epoch: 38, Batch: 200, MLM Loss: 5.144018228054047, NSP Loss:0.5866935238242149\n",
            "Epoch: 38, Batch: 400, MLM Loss: 5.15100323677063, NSP Loss:0.5848240322619677\n",
            "Epoch: 38, Batch: 600, MLM Loss: 5.156507165431976, NSP Loss:0.5825518396993478\n",
            "Epoch: 38, Batch: 800, MLM Loss: 5.158066917657852, NSP Loss:0.5822218393534422\n",
            "Epoch: 38, Batch: 1000, MLM Loss: 5.160829006671905, NSP Loss:0.5829741241037846\n",
            "Epoch: 38, Batch: 1200, MLM Loss: 5.162320018609365, NSP Loss:0.5829469861835241\n",
            "Train ===> Epoch 39 Loss: 5.743488594508744\n",
            "Val ---> Epoch 39, Val_NSP_Accuracy: 0.6926130652427673\n",
            "------------------------------\n",
            "Epoch: 39, Batch: 200, MLM Loss: 5.139241058826446, NSP Loss:0.570362126082182\n",
            "Epoch: 39, Batch: 400, MLM Loss: 5.14995491027832, NSP Loss:0.574768621623516\n",
            "Epoch: 39, Batch: 600, MLM Loss: 5.1496644926071165, NSP Loss:0.5757709229489167\n",
            "Epoch: 39, Batch: 800, MLM Loss: 5.155586906075477, NSP Loss:0.5770659535005689\n",
            "Epoch: 39, Batch: 1000, MLM Loss: 5.155074810504913, NSP Loss:0.5776571264266968\n",
            "Epoch: 39, Batch: 1200, MLM Loss: 5.155072254339854, NSP Loss:0.5789646458874146\n",
            "Train ===> Epoch 40 Loss: 5.732929959904769\n",
            "Val ---> Epoch 40, Val_NSP_Accuracy: 0.7136796712875366\n",
            "------------------------------\n",
            "Epoch: 40, Batch: 200, MLM Loss: 5.1446979928016665, NSP Loss:0.5710673606395722\n",
            "Epoch: 40, Batch: 400, MLM Loss: 5.141848077774048, NSP Loss:0.5739024548232555\n",
            "Epoch: 40, Batch: 600, MLM Loss: 5.1379411848386125, NSP Loss:0.5751448492705822\n",
            "Epoch: 40, Batch: 800, MLM Loss: 5.142918553948403, NSP Loss:0.5764470883086323\n",
            "Epoch: 40, Batch: 1000, MLM Loss: 5.1429554133415225, NSP Loss:0.5757490624785423\n",
            "Epoch: 40, Batch: 1200, MLM Loss: 5.140290418068568, NSP Loss:0.5752559010187784\n",
            "Train ===> Epoch 41 Loss: 5.714428430490952\n",
            "Val ---> Epoch 41, Val_NSP_Accuracy: 0.7202327251434326\n",
            "------------------------------\n",
            "Epoch: 41, Batch: 200, MLM Loss: 5.1276094794273375, NSP Loss:0.5753863199055195\n",
            "Epoch: 41, Batch: 400, MLM Loss: 5.133629298210144, NSP Loss:0.5724491222947836\n",
            "Epoch: 41, Batch: 600, MLM Loss: 5.1258485253651935, NSP Loss:0.5714282296597958\n",
            "Epoch: 41, Batch: 800, MLM Loss: 5.124902693629265, NSP Loss:0.5708029896765947\n",
            "Epoch: 41, Batch: 1000, MLM Loss: 5.127851767539978, NSP Loss:0.5700673065781593\n",
            "Epoch: 41, Batch: 1200, MLM Loss: 5.128337454398473, NSP Loss:0.5707654554645221\n",
            "Train ===> Epoch 42 Loss: 5.698591231122486\n",
            "Val ---> Epoch 42, Val_NSP_Accuracy: 0.7192876935005188\n",
            "------------------------------\n",
            "Epoch: 42, Batch: 200, MLM Loss: 5.134741334915161, NSP Loss:0.5667865771055222\n",
            "Epoch: 42, Batch: 400, MLM Loss: 5.123304935693741, NSP Loss:0.564411843791604\n",
            "Epoch: 42, Batch: 600, MLM Loss: 5.127523923714955, NSP Loss:0.5634571296473344\n",
            "Epoch: 42, Batch: 800, MLM Loss: 5.127882902026176, NSP Loss:0.564012688100338\n",
            "Epoch: 42, Batch: 1000, MLM Loss: 5.12675377368927, NSP Loss:0.5659642549157142\n",
            "Epoch: 42, Batch: 1200, MLM Loss: 5.126340259313583, NSP Loss:0.5667355460673571\n",
            "Train ===> Epoch 43 Loss: 5.69369309214914\n",
            "Val ---> Epoch 43, Val_NSP_Accuracy: 0.7170411348342896\n",
            "------------------------------\n",
            "Epoch: 43, Batch: 200, MLM Loss: 5.127408618927002, NSP Loss:0.5587023031711579\n",
            "Epoch: 43, Batch: 400, MLM Loss: 5.130189198255539, NSP Loss:0.5606081635504961\n",
            "Epoch: 43, Batch: 600, MLM Loss: 5.1320517635345455, NSP Loss:0.5627887552976608\n",
            "Epoch: 43, Batch: 800, MLM Loss: 5.129322150349617, NSP Loss:0.5627425822243094\n",
            "Epoch: 43, Batch: 1000, MLM Loss: 5.125338455677032, NSP Loss:0.5617287369370461\n",
            "Epoch: 43, Batch: 1200, MLM Loss: 5.1184625430901844, NSP Loss:0.561486470947663\n",
            "Train ===> Epoch 44 Loss: 5.6802682156575734\n",
            "Val ---> Epoch 44, Val_NSP_Accuracy: 0.6989490389823914\n",
            "------------------------------\n",
            "Epoch: 44, Batch: 200, MLM Loss: 5.1379088377952575, NSP Loss:0.5552097773551941\n",
            "Epoch: 44, Batch: 400, MLM Loss: 5.134556978940964, NSP Loss:0.5592366203665733\n",
            "Epoch: 44, Batch: 600, MLM Loss: 5.123608716328939, NSP Loss:0.5620612967511018\n",
            "Epoch: 44, Batch: 800, MLM Loss: 5.119840812087059, NSP Loss:0.5621969119086861\n",
            "Epoch: 44, Batch: 1000, MLM Loss: 5.1142222099304195, NSP Loss:0.5615295121967793\n",
            "Epoch: 44, Batch: 1200, MLM Loss: 5.116052214304606, NSP Loss:0.5622581565131743\n",
            "Train ===> Epoch 45 Loss: 5.675487837664016\n",
            "Val ---> Epoch 45, Val_NSP_Accuracy: 0.7256045341491699\n",
            "------------------------------\n",
            "Epoch: 45, Batch: 200, MLM Loss: 5.1220536804199215, NSP Loss:0.5505773696303368\n",
            "Epoch: 45, Batch: 400, MLM Loss: 5.11810041308403, NSP Loss:0.5543701418489217\n",
            "Epoch: 45, Batch: 600, MLM Loss: 5.114621754487356, NSP Loss:0.5536293523510297\n",
            "Epoch: 45, Batch: 800, MLM Loss: 5.106008281707764, NSP Loss:0.5533548853546381\n",
            "Epoch: 45, Batch: 1000, MLM Loss: 5.1023528823852535, NSP Loss:0.5545118595659733\n",
            "Epoch: 45, Batch: 1200, MLM Loss: 5.102202049891154, NSP Loss:0.5544027363757292\n",
            "Train ===> Epoch 46 Loss: 5.65668588313458\n",
            "Val ---> Epoch 46, Val_NSP_Accuracy: 0.737406849861145\n",
            "------------------------------\n",
            "Epoch: 46, Batch: 200, MLM Loss: 5.118623158931732, NSP Loss:0.5533688212931156\n",
            "Epoch: 46, Batch: 400, MLM Loss: 5.096378947496414, NSP Loss:0.5499014963954687\n",
            "Epoch: 46, Batch: 600, MLM Loss: 5.09089262564977, NSP Loss:0.5532250958681106\n",
            "Epoch: 46, Batch: 800, MLM Loss: 5.092342036366463, NSP Loss:0.5544323897361756\n",
            "Epoch: 46, Batch: 1000, MLM Loss: 5.090263259410858, NSP Loss:0.5541430020332336\n",
            "Epoch: 46, Batch: 1200, MLM Loss: 5.091901299556096, NSP Loss:0.553671426375707\n",
            "Train ===> Epoch 47 Loss: 5.646381907551719\n",
            "Val ---> Epoch 47, Val_NSP_Accuracy: 0.7186622619628906\n",
            "------------------------------\n",
            "Epoch: 47, Batch: 200, MLM Loss: 5.1235689091682435, NSP Loss:0.550993422716856\n",
            "Epoch: 47, Batch: 400, MLM Loss: 5.1140920400619505, NSP Loss:0.5480601290613413\n",
            "Epoch: 47, Batch: 600, MLM Loss: 5.103499654928843, NSP Loss:0.5471984209120273\n",
            "Epoch: 47, Batch: 800, MLM Loss: 5.099625630378723, NSP Loss:0.547754992544651\n",
            "Epoch: 47, Batch: 1000, MLM Loss: 5.0951249904632565, NSP Loss:0.5481085938215255\n",
            "Epoch: 47, Batch: 1200, MLM Loss: 5.092075157165527, NSP Loss:0.5485325465351343\n",
            "Train ===> Epoch 48 Loss: 5.642438334402052\n",
            "Val ---> Epoch 48, Val_NSP_Accuracy: 0.7306354641914368\n",
            "------------------------------\n",
            "Epoch: 48, Batch: 200, MLM Loss: 5.083105373382568, NSP Loss:0.5455302521586418\n",
            "Epoch: 48, Batch: 400, MLM Loss: 5.07046439409256, NSP Loss:0.5448780463635922\n",
            "Epoch: 48, Batch: 600, MLM Loss: 5.076551832358042, NSP Loss:0.54593882655104\n",
            "Epoch: 48, Batch: 800, MLM Loss: 5.082575702667237, NSP Loss:0.5457785844057799\n",
            "Epoch: 48, Batch: 1000, MLM Loss: 5.075994649410248, NSP Loss:0.5456360882818699\n",
            "Epoch: 48, Batch: 1200, MLM Loss: 5.072705971399943, NSP Loss:0.5461643593758345\n",
            "Train ===> Epoch 49 Loss: 5.620793306047283\n",
            "Val ---> Epoch 49, Val_NSP_Accuracy: 0.7269837856292725\n",
            "------------------------------\n",
            "Epoch: 49, Batch: 200, MLM Loss: 5.095317742824554, NSP Loss:0.5435925230383873\n",
            "Epoch: 49, Batch: 400, MLM Loss: 5.087780647277832, NSP Loss:0.5425863565504551\n",
            "Epoch: 49, Batch: 600, MLM Loss: 5.088355308373769, NSP Loss:0.5430876035491625\n",
            "Epoch: 49, Batch: 800, MLM Loss: 5.084600323438645, NSP Loss:0.5442017900943756\n",
            "Epoch: 49, Batch: 1000, MLM Loss: 5.08098776102066, NSP Loss:0.5438290767669678\n",
            "Epoch: 49, Batch: 1200, MLM Loss: 5.078663540283839, NSP Loss:0.5434140432377657\n",
            "Train ===> Epoch 50 Loss: 5.62031185786268\n",
            "Val ---> Epoch 50, Val_NSP_Accuracy: 0.7427527904510498\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NSP ê²°ê³¼ë¥¼ í‰ê°€"
      ],
      "metadata": {
        "id": "o9E4IRuyX9NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eps = range(len(train_loss))\n",
        "\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1.plot(eps, train_loss, label = 'train_loss')\n",
        "ax1.legend()\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "ax2.plot(eps, test_acc, label = 'test_acc')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "vEfdMhkLYWV1",
        "outputId": "8d0e2e19-6c5c-4e50-d973-d9a6611ad914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train LossëŠ” ì§€ì†ì ìœ¼ë¡œ ê°ì†Œí•˜ë©°, Test AccuracyëŠ” ê¾¸ì¤€íˆ ì¦ê°€í•˜ì—¬ ì•½ 80%ê¹Œì§€ ë„ë‹¬í•©ë‹ˆë‹¤.\n",
        "ì´ëŠ” ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµë˜ì—ˆê³ , ê³¼ì í•© ì—†ì´ ì¼ë°˜í™” ì„±ëŠ¥ì´ í–¥ìƒë˜ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "64mBUmCiYlV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (inp, labels, mask) in enumerate(val_loader):\n",
        "        inp = inp.long().to(device)\n",
        "        labels = labels.to(device)\n",
        "        mask = mask.to(device)\n",
        "        mlm_logits, nsp_logits = model(inp, mask)\n",
        "        cls = nsp_logits.argmax(dim=1)\n",
        "        encode = inp.cpu().tolist()\n",
        "        print(list(encode))\n",
        "        print(f'ì…ë ¥: {sp.decode(list(encode))}')\n",
        "        print(f'ë ˆì´ë¸”: {labels}')\n",
        "        print(f'ì˜ˆì¸¡: {cls}')\n",
        "        if i > 10:\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHKg9FhRYrFi",
        "outputId": "2bdf6e89-dfc9-4d3f-bb4c-5d08837e2617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 193, 305, 25, 1112, 176, 339, 953, 3, 2, 154, 1130, 8, 4, 709, 709, 2526, 5, 72, 783, 3, 3428, 99, 474, 4, 87, 70, 154, 6, 4, 3969, 13, 1696, 1745, 21, 1262, 3, 1295, 10, 968, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì€í‡´ í›„ì˜ ì‚¶ì´ ì°¸ ê±±ì •ì´ ë˜ë„¤ â‡  ë‚¨í¸ë¶„ì´ ë“ ë“ í•˜ì‹ ê°€ ë´ìš” â‡  íŠ¹ë³„íˆ ì–´ë–¤ ë©´ì—ì„œ ë‚¨í¸ì„ ë¯¿ê³  ì˜ì§€í•˜ì‹œëŠ”ì§€ ì—¬ â‡ ë´ë„ ë ê¹Œìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([0], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([1], device='cuda:0')\n",
            "[[1, 372, 990, 7, 2999, 104, 128, 159, 97, 3, 1880, 8, 90, 202, 112, 3, 2, 464, 5, 150, 120, 2901, 186, 1714, 6, 147, 701, 155, 1745, 760, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì¹œêµ¬ì—ê²Œ ì‚¬ê¸°ë¥¼ ë‹¹í–ˆëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ â‡  í°ì¼ì´ ë‚ ê¹Œ ë¶ˆì•ˆí•´ â‡  ì¥ì• ê°€ ìˆì–´ì„œ ì¹œêµ¬ë“¤ì´ ì‚¬ìš©ìë‹˜ì„ ì‹«ì–´í•œë‹¤ê³  ìƒê°í•˜ì‹œëŠ”êµ°ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([0], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([0], device='cuda:0')\n",
            "[[1, 29, 154, 20, 192, 381, 7, 37, 4, 1009, 268, 64, 626, 13, 217, 3, 2, 89, 381, 7, 37, 4, 1009, 268, 64, 626, 13, 1672, 1605, 760, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ìš”ì¦˜ ë‚¨í¸ì€ ë‚˜ì™€ ëŒ€í™”ë¥¼ ì˜ í•˜ë ¤ í•˜ì§€ ì•Šì•„ ì™¸ë¡­ê³  ìš°ìš¸í•´ â‡  ë‚¨í¸ì´ ëŒ€í™”ë¥¼ ì˜ í•˜ë ¤ í•˜ì§€ ì•Šì•„ ì™¸ë¡­ê³  ìš°ìš¸í•˜ì…¨êµ°ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([1], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([1], device='cuda:0')\n",
            "[[1, 271, 61, 178, 561, 243, 43, 11, 7, 1241, 3, 2786, 742, 3, 2, 271, 1863, 13, 561, 1404, 2786, 985, 252, 143, 14, 760, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ìì‹ë“¤ì´ ì´ì œ ë‚˜ì—ê²Œ ë§‰ ëŒ€í•˜ê³  ë‚˜ë¥¼ ë¬´ì‹œí•´ â‡  í•™ëŒ€ë°›ëŠ” ëŠë‚Œì´ì•¼ â‡  ìì‹ë“¤ì´ ë¬´ì‹œí•˜ê³  ë§‰ ëŒ€í•´ì„œ í•™ëŒ€ë°›ëŠ” ëŠë‚Œì´ ë“œì‹œëŠ”êµ°ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([1], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([1], device='cuda:0')\n",
            "[[1, 442, 2171, 167, 24, 893, 207, 294, 9, 19, 1737, 3, 2, 1110, 6, 573, 4, 572, 12, 12, 214, 597, 4, 572, 308, 63, 22, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì•„ë‚´ì™€ ì´í˜¼í•˜ê³  ì§‘ì—ë§Œ ìˆì—ˆë”ë‹ˆ ê±´ê°•ì´ ë„ˆë¬´ ì•ˆ ì¢‹ì•„ì¡Œì–´ â‡  í‡´ê·¼ì„ ëª»í•˜ê³  ê³„ì„œì„œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ê³  ê³„ì‹  ê±° ê°™ì•„ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([0], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([0], device='cuda:0')\n",
            "[[1, 820, 25, 619, 26, 7, 961, 807, 677, 641, 30, 117, 19, 267, 1317, 133, 1737, 3, 2, 820, 619, 26, 1278, 15, 133, 71, 21, 1605, 760, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì„ ìƒë‹˜ì˜ ìœ„ë¡œë¥¼ ë“£ê³  ë‚˜ë‹ˆ ì¡°ê¸‰í•œ ë§ˆìŒì´ ì•ˆì •ë˜ê³  ê¸°ë¶„ì´ ì¢‹ì•„ì¡Œì–´ â‡  ì„ ìƒë‹˜ ìœ„ë¡œ ë•ë¶„ì— ê¸°ë¶„ì´ ì¢‹ì•„ì§€ì…¨êµ°ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([1], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([1], device='cuda:0')\n",
            "[[1, 1769, 7, 2706, 10, 83, 2017, 39, 3, 2572, 34, 3223, 3, 2, 1357, 213, 473, 12, 176, 652, 143, 427, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì´ë ¥ì„œë¥¼ ë„£ì–´ë„ ìê¾¸ íƒˆë½í•´ â‡  ì·¨ì—…í•˜ê¸° ì •ë§ ì–´ë µë‹¤ â‡  ìˆ˜í•™ ì„±ì ì´ ë–¨ì–´ì ¸ì„œ ì°¸ ìŠ¬í”„ì‹œê² ì–´ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([0], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([0], device='cuda:0')\n",
            "[[1, 32, 515, 852, 30, 101, 1808, 3, 9, 2737, 3, 2, 102, 10, 2166, 7, 3406, 21, 188, 4, 3990, 799, 342, 18, 22, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì˜¤ëŠ˜ ë™ìƒì´ ê±°ì§“ë§í•œ ê±¸ ì•Œì•˜ì–´ â‡  ë„ˆë¬´ ì‹¤ë§ì´ì•¼ â‡  ì•„ë¬´ë„ ê°•ì•„ì§€ë¥¼ ëŒë´ì£¼ì§€ ì•Šì•„ì„œ í˜ë“œì‹¤ ê²ƒ ê°™ì•„ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([0], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([0], device='cuda:0')\n",
            "[[1, 1139, 14, 16, 1091, 3966, 20, 21, 104, 709, 187, 4, 3176, 40, 11, 7, 4, 3855, 168, 471, 13, 121, 68, 1178, 3, 2, 187, 4, 3176, 40, 4, 3855, 168, 471, 13, 121, 94, 1139, 5, 569, 245, 143, 760, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ë©°ëŠë¦¬ëŠ” ë‚´ê°€ ê·€ì°®ì€ì§€ ì–´ë–»ê²Œë“  ì§‘ ë°–ìœ¼ë¡œ ë‚˜ë¥¼ ì«“ì•„ë‚´ê³  ì‹¶ì–´ í•´ì„œ ë¯¸ì›Œ â‡  ì§‘ ë°–ìœ¼ë¡œ ì«“ì•„ë‚´ê³  ì‹¶ì–´ í•˜ëŠ” ë©°ëŠë¦¬ê°€ ë¯¸ìš°ì‹œêµ°ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([1], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([1], device='cuda:0')\n",
            "[[1, 737, 1762, 1016, 369, 4, 1913, 3576, 186, 7, 1192, 14, 17, 111, 3389, 3, 2, 1657, 887, 774, 498, 1034, 70, 1998, 1221, 6, 2609, 3145, 14, 760, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì‹œë¯¼ë“¤ì„ ìœ„í•´ ë²”ì£„ìë¥¼ ì¡ëŠ” ë‚´ ì¼ì´ ìë‘ìŠ¤ëŸ¬ì›Œ â‡  ì‹ ì²´ ë¬¸ì œë¡œ ì¸í•´ ìƒí™œ ì†ì—ì„œ ë¶ˆí¸í•œ ê°ì •ì„ ëŠë¼ê³  ê³„ì‹œëŠ”êµ°ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([0], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([0], device='cuda:0')\n",
            "[[1, 32, 1150, 518, 3, 1361, 5, 4, 3953, 45, 1921, 72, 558, 3, 2, 1150, 802, 53, 2586, 143, 760, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ì˜¤ëŠ˜ ë‚¨ìì¹œêµ¬ì™€ ì‹¸ì› ì–´ â‡  ì´ëŸ¬ë‹¤ê°€ í—¤ì–´ì§ˆê¹Œ ë´ ì´ˆì¡°í•´ â‡  ë‚¨ìì¹œêµ¬ì™€ ì‹¸ì›Œ ë§ì´ ì´ˆì¡°í•˜ì‹œêµ°ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([1], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([0], device='cuda:0')\n",
            "[[1, 252, 378, 1506, 609, 70, 296, 2917, 609, 40, 138, 1485, 8, 276, 3, 330, 715, 117, 3186, 3, 2, 117, 3186, 435, 2352, 15, 783, 3, 61, 14, 4, 3940, 74, 4, 3987, 689, 595, 783, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "ì…ë ¥: ['ë“œë””ì–´ ê³„ì•½ì§ì—ì„œ ì •ê·œì§ìœ¼ë¡œ ì „í™˜ì´ ëì–´ â‡  ê·¸ë˜ì„œ ê·¸ëŸ°ì§€ ë§ˆìŒì´ ëŠê¸‹í•´ â‡  ë§ˆìŒì´ ëŠê¸‹í•´ì ¸ì„œ ë‹¤í–‰ì´ì—ìš” â‡  ì´ì œëŠ” ë­˜ í•˜ê³  ì‹¶ìœ¼ì„¸ìš” â‡ ']\n",
            "ë ˆì´ë¸”: tensor([1], device='cuda:0')\n",
            "ì˜ˆì¸¡: tensor([1], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NSP ë¼ë²¨ì—ì„œ 0ê³¼ 1ì˜ ì˜ë¯¸\n",
        "\n",
        "- 0 = Not Matched Sentence (ì—°ì†ëœ ë¬¸ì¥ ì•„ë‹˜)\n",
        "- 1 = Matched Sentence (ì—°ì†ëœ ë¬¸ì¥)\n",
        "\n"
      ],
      "metadata": {
        "id": "-XoQLvNjaKub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ ì˜ˆì‹œë“¤ì„ ë³´ë©´ ëŒ€ë¶€ë¶„ ë ˆì´ë¸”ê³¼ ì˜ˆì¸¡ì´ ì¼ì¹˜í•´ì„œ NSP íŒ¨í„´ì„ ê½¤ ì˜ í•™ìŠµí•œ ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ë§Œ ë§ˆì§€ë§‰ì²˜ëŸ¼ ê¸ì •Â·ì•ˆì • ê°ì •ì´ ì„ì¸ ë¬¸ì¥ì€ 0ê³¼ 1ì„ í—·ê°ˆë ¤ í•˜ëŠ” ì˜¤ë¶„ë¥˜ê°€ ë‚¨ì•„ ìˆì–´, ì¶”ê°€ ë°ì´í„°ë‚˜ íŠœë‹ ì—¬ì§€ê°€ ìˆë‹¤ëŠ” ì •ë„ë¡œ í•´ì„í•˜ë©´ ë  ê²ƒ ê°™ì•„ìš”."
      ],
      "metadata": {
        "id": "_372S5ZzbI-e"
      }
    }
  ]
}