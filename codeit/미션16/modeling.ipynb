{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PyTorch ëª¨ë¸ ì €ì¥, ì–‘ìí™”, ONNX ë³€í™˜ "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.quantization\n",
                "import onnx\n",
                "import onnxruntime as ort\n",
                "import numpy as np\n",
                "import time\n",
                "from pathlib import Path\n",
                "\n",
                "# ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
                "save_dir = Path('mlp_models')\n",
                "save_dir.mkdir(exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SimpleMLP ëª¨ë¸ ì •ì˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleMLP(nn.Module):\n",
                "    def __init__(self, input_size=784, hidden_size=256, num_classes=10):\n",
                "        super(SimpleMLP, self).__init__()\n",
                "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.dropout = nn.Dropout(0.2)\n",
                "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = x.view(x.size(0), -1)  # Flatten\n",
                "        x = self.fc1(x)\n",
                "        x = self.relu(x)\n",
                "        x = self.dropout(x)\n",
                "        x = self.fc2(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# í•™ìŠµ "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° ë¡œë” ì¤€ë¹„ (MNIST ì˜ˆì‹œ)\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
                "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸš€ í•™ìŠµ ì‹œì‘...\n",
                        "\n",
                        "Epoch 1/5 - Loss: 0.2467, Accuracy: 92.67%\n",
                        "Epoch 2/5 - Loss: 0.1159, Accuracy: 96.47%\n",
                        "Epoch 3/5 - Loss: 0.0882, Accuracy: 97.19%\n",
                        "Epoch 4/5 - Loss: 0.0688, Accuracy: 97.81%\n",
                        "Epoch 5/5 - Loss: 0.0598, Accuracy: 97.99%\n",
                        "\n",
                        "âœ… í•™ìŠµ ì™„ë£Œ!\n"
                    ]
                }
            ],
            "source": [
                "# ëª¨ë¸ í•™ìŠµ\n",
                "model = SimpleMLP()\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
                "\n",
                "print(\"ğŸš€ í•™ìŠµ ì‹œì‘...\\n\")\n",
                "for epoch in range(5):\n",
                "    model.train()  # âœ… í•™ìŠµ ëª¨ë“œ ì„¤ì •\n",
                "    epoch_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    for batch_idx, (x, y) in enumerate(train_loader):\n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        # Forward pass\n",
                "        outputs = model(x)\n",
                "        loss = criterion(outputs, y)\n",
                "        \n",
                "        # Backward pass\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        # í†µê³„\n",
                "        epoch_loss += loss.item()\n",
                "        _, predicted = outputs.max(1)\n",
                "        total += y.size(0)\n",
                "        correct += predicted.eq(y).sum().item()\n",
                "    \n",
                "    # ì—í­ë³„ ê²°ê³¼ ì¶œë ¥\n",
                "    avg_loss = epoch_loss / len(train_loader)\n",
                "    accuracy = 100. * correct / total\n",
                "    print(f\"Epoch {epoch+1}/5 - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
                "\n",
                "print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1ï¸âƒ£ ëª¨ë¸ ì €ì¥"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: mlp_models\\model_weights.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 797.52 KB\n",
                        "\n",
                        "ğŸ“¦ ì „ì²´ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: mlp_models\\model.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 798.51 KB\n",
                        "\n",
                        "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: mlp_models\\checkpoint.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 2390.80 KB\n"
                    ]
                }
            ],
            "source": [
                "# ë°©ë²• 1: ê°€ì¤‘ì¹˜ë§Œ ì €ì¥ (ê¶Œì¥ âœ…)\n",
                "weights_path = save_dir / 'model_weights.pth'\n",
                "torch.save(model.state_dict(), weights_path)\n",
                "print(f\"âœ… ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: {weights_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {weights_path.stat().st_size / 1024:.2f} KB\\n\")\n",
                "\n",
                "# ë°©ë²• 2: ëª¨ë¸ ì „ì²´ ì €ì¥\n",
                "full_model_path = save_dir / 'model.pth'\n",
                "torch.save(model, full_model_path)\n",
                "print(f\"ğŸ“¦ ì „ì²´ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {full_model_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {full_model_path.stat().st_size / 1024:.2f} KB\\n\")\n",
                "\n",
                "# ë°©ë²• 3: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (í•™ìŠµ ì¬ê°œìš©)\n",
                "checkpoint_path = save_dir / 'checkpoint.pth'\n",
                "torch.save({\n",
                "    'epoch': 5,\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'optimizer_state_dict': optimizer.state_dict(),\n",
                "    'loss': avg_loss,\n",
                "}, checkpoint_path)\n",
                "print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {checkpoint_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {checkpoint_path.stat().st_size / 1024:.2f} KB\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2ï¸âƒ£ ì–‘ìí™” (Quantization)\n",
                "## Dynamic Quantization (ë™ì  ì–‘ìí™”) ì¤‘ Eager Mode / Post-Training Quantization\n",
                "### ëª¨ë¸ í¬ê¸° ê°ì†Œ ë° ì¶”ë¡  ì†ë„ í–¥ìƒ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âš¡ ì–‘ìí™” ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: mlp_models\\model_quantized_weights.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 203.54 KB\n",
                        "   ì••ì¶•ë¥ : 3.92x\n",
                        "\n",
                        "âš¡ ì–‘ìí™” ëª¨ë¸ ì „ì²´ ì €ì¥ ì™„ë£Œ: mlp_models\\model_quantized.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 203.98 KB\n",
                        "   ì••ì¶•ë¥ : 3.91x\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# ë™ì  ì–‘ìí™” (Dynamic Quantization)\n",
                "model.eval()\n",
                "quantized_model = torch.quantization.quantize_dynamic(\n",
                "    model,\n",
                "    {nn.Linear},  # ì–‘ìí™”í•  ë ˆì´ì–´ íƒ€ì…\n",
                "    dtype=torch.qint8\n",
                ")\n",
                "\n",
                "# ì–‘ìí™” ëª¨ë¸ ì €ì¥\n",
                "quantized_path = save_dir / 'model_quantized_weights.pth'\n",
                "torch.save(quantized_model.state_dict(), quantized_path)\n",
                "print(f\"âš¡ ì–‘ìí™” ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: {quantized_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {quantized_path.stat().st_size / 1024:.2f} KB\")\n",
                "print(f\"   ì••ì¶•ë¥ : {weights_path.stat().st_size / quantized_path.stat().st_size:.2f}x\\n\")\n",
                "\n",
                "full_quantized_path = save_dir / 'model_quantized.pth'\n",
                "torch.save(quantized_model, full_quantized_path)\n",
                "# torch.save(quantized_model, str(quantized_path) + '_full')\n",
                "# torch.save(quantized_model, quantized_path.with_name(quantized_path.stem + '_full.pth'))\n",
                "print(f\"âš¡ ì–‘ìí™” ëª¨ë¸ ì „ì²´ ì €ì¥ ì™„ë£Œ: {full_quantized_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {full_quantized_path.stat().st_size / 1024:.2f} KB\")\n",
                "print(f\"   ì••ì¶•ë¥ : {full_model_path.stat().st_size / full_quantized_path.stat().st_size:.2f}x\\n\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "FP32 â†’ INT8 ì´ë¡ ì  ìµœëŒ€ ì••ì¶•ë¥  â‰ˆ 4x\n",
                "\n",
                "ê²°ê³¼: 3.9\n",
                "â†’ ê±°ì˜ ì´ë¡ ì  ìµœëŒ€ì¹˜"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3ï¸âƒ£ ONNX ë³€í™˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ”„ ONNX ë³€í™˜ ì™„ë£Œ: mlp_models\\model.onnx\n",
                        "   íŒŒì¼ í¬ê¸°: 796.04 KB\n",
                        "\n",
                        "âœ… ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ\n"
                    ]
                }
            ],
            "source": [
                "# ONNXë¡œ ë³€í™˜\n",
                "model.eval()\n",
                "dummy_input = torch.randn(1, 1, 28, 28)  # MNIST ì…ë ¥ í¬ê¸°\n",
                "onnx_path = save_dir / 'model.onnx'\n",
                "\n",
                "torch.onnx.export(\n",
                "    model,\n",
                "    dummy_input,\n",
                "    onnx_path,\n",
                "    export_params=True,\n",
                "    opset_version=11,\n",
                "    do_constant_folding=True,\n",
                "    input_names=['input'],\n",
                "    output_names=['output'],\n",
                "    dynamo=False,  # âœ… ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥\n",
                "    dynamic_axes={\n",
                "        'input': {0: 'batch_size'},\n",
                "        'output': {0: 'batch_size'}\n",
                "    }\n",
                ")\n",
                "\n",
                "\n",
                "print(f\"ğŸ”„ ONNX ë³€í™˜ ì™„ë£Œ: {onnx_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {onnx_path.stat().st_size / 1024:.2f} KB\\n\")\n",
                "\n",
                "# ONNX ëª¨ë¸ ê²€ì¦\n",
                "onnx_model = onnx.load(onnx_path)\n",
                "onnx.checker.check_model(onnx_model)\n",
                "print(\"âœ… ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ\n",
                        "\n"
                    ]
                },
                {
                    "ename": "UnpicklingError",
                    "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch.nn.modules.linear.Linear was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torch.nn.modules.linear.Linear])` or the `torch.serialization.safe_globals([torch.nn.modules.linear.Linear])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ì „ì²´\u001b[39;00m\n\u001b[32m     14\u001b[39m full_model_path = save_dir / \u001b[33m'\u001b[39m\u001b[33mmodel.pth\u001b[39m\u001b[33m'\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (í•™ìŠµ ì¬ê°œìš©)\u001b[39;00m\n\u001b[32m     18\u001b[39m checkpoint = torch.load(checkpoint_path)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32me:\\python_conda_jupyter\\.venv\\Lib\\site-packages\\torch\\serialization.py:1524\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1516\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m                     opened_zipfile,\n\u001b[32m   1518\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1521\u001b[39m                     **pickle_load_args,\n\u001b[32m   1522\u001b[39m                 )\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
                        "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch.nn.modules.linear.Linear was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torch.nn.modules.linear.Linear])` or the `torch.serialization.safe_globals([torch.nn.modules.linear.Linear])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
                    ]
                }
            ],
            "source": [
                "# ëª¨ë¸ ë¡œë“œ ì˜ˆì‹œ\n",
                "# ê°€ì¤‘ì¹˜ ë¡œë“œ (ê¶Œì¥)\n",
                "# weights_path=save_dir/'model_weights.pth'\n",
                "loaded_model = SimpleMLP()\n",
                "loaded_model.load_state_dict(torch.load(weights_path))\n",
                "loaded_model.eval()\n",
                "print(\"âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ\\n\")\n",
                "\n",
                "from torch.serialization import add_safe_globals\n",
                "# SimpleMLP í´ë˜ìŠ¤ ì •ì˜ê°€ í˜„ì¬ ì½”ë“œì— ìˆì–´ì•¼ í•¨\n",
                "add_safe_globals([SimpleMLP])\n",
                "# ì „ì²´\n",
                "full_model_path = save_dir / 'model.pth' \n",
                "model = torch.load(full_model_path)\n",
                "# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (í•™ìŠµ ì¬ê°œìš©)\n",
                "checkpoint = torch.load(checkpoint_path)\n",
                "resume_model = SimpleMLP()\n",
                "resume_model.load_state_dict(checkpoint['model_state_dict'])\n",
                "resume_optimizer = torch.optim.Adam(resume_model.parameters())\n",
                "resume_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
                "resume_epoch = checkpoint['epoch']\n",
                "resume_loss = checkpoint['loss']\n",
                "print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ (Epoch {resume_epoch}, Loss {resume_loss:.4f})\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
