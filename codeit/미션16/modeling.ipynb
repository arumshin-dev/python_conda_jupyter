{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PyTorch ëª¨ë¸ ì €ì¥, ì–‘ìí™”, ONNX ë³€í™˜ "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.quantization\n",
                "import onnx\n",
                "import onnxruntime as ort\n",
                "import numpy as np\n",
                "import time\n",
                "from pathlib import Path\n",
                "\n",
                "# ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
                "save_dir = Path('mlp_models')\n",
                "save_dir.mkdir(exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SimpleMLP ëª¨ë¸ ì •ì˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleMLP(nn.Module):\n",
                "    def __init__(self, input_size=784, hidden_size=256, num_classes=10):\n",
                "        super(SimpleMLP, self).__init__()\n",
                "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.dropout = nn.Dropout(0.2)\n",
                "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = x.view(x.size(0), -1)  # Flatten\n",
                "        x = self.fc1(x)\n",
                "        x = self.relu(x)\n",
                "        x = self.dropout(x)\n",
                "        x = self.fc2(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# í•™ìŠµ "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„° ë¡œë” ì¤€ë¹„ (MNIST ì˜ˆì‹œ)\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
                "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸš€ í•™ìŠµ ì‹œì‘...\n",
                        "\n",
                        "Epoch 1/5 - Loss: 0.2468, Accuracy: 92.55%\n",
                        "Epoch 2/5 - Loss: 0.1145, Accuracy: 96.51%\n",
                        "Epoch 3/5 - Loss: 0.0869, Accuracy: 97.27%\n",
                        "Epoch 4/5 - Loss: 0.0704, Accuracy: 97.78%\n",
                        "Epoch 5/5 - Loss: 0.0600, Accuracy: 98.06%\n",
                        "\n",
                        "âœ… í•™ìŠµ ì™„ë£Œ!\n"
                    ]
                }
            ],
            "source": [
                "# ëª¨ë¸ í•™ìŠµ\n",
                "model = SimpleMLP()\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
                "\n",
                "print(\"ğŸš€ í•™ìŠµ ì‹œì‘...\\n\")\n",
                "for epoch in range(5):\n",
                "    model.train()  # âœ… í•™ìŠµ ëª¨ë“œ ì„¤ì •\n",
                "    epoch_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    for batch_idx, (x, y) in enumerate(train_loader):\n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        # Forward pass\n",
                "        outputs = model(x)\n",
                "        loss = criterion(outputs, y)\n",
                "        \n",
                "        # Backward pass\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        # í†µê³„\n",
                "        epoch_loss += loss.item()\n",
                "        _, predicted = outputs.max(1)\n",
                "        total += y.size(0)\n",
                "        correct += predicted.eq(y).sum().item()\n",
                "    \n",
                "    # ì—í­ë³„ ê²°ê³¼ ì¶œë ¥\n",
                "    avg_loss = epoch_loss / len(train_loader)\n",
                "    accuracy = 100. * correct / total\n",
                "    print(f\"Epoch {epoch+1}/5 - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
                "\n",
                "print(\"\\nâœ… í•™ìŠµ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1ï¸âƒ£ ëª¨ë¸ ì €ì¥"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: mlp_models\\mission_16_original.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 797.58 KB\n",
                        "\n",
                        "ğŸ“¦ ì „ì²´ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: mlp_models\\model.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 798.51 KB\n",
                        "\n",
                        "ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: mlp_models\\checkpoint.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 2390.80 KB\n"
                    ]
                }
            ],
            "source": [
                "# ë°©ë²• 1: ê°€ì¤‘ì¹˜ë§Œ ì €ì¥ (ê¶Œì¥ âœ…)\n",
                "weights_path = save_dir / 'mission_16_original.pth'\n",
                "torch.save(model.state_dict(), weights_path)\n",
                "print(f\"âœ… ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: {weights_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {weights_path.stat().st_size / 1024:.2f} KB\\n\")\n",
                "\n",
                "# ë°©ë²• 2: ëª¨ë¸ ì „ì²´ ì €ì¥\n",
                "full_model_path = save_dir / 'model.pth'\n",
                "torch.save(model, full_model_path)\n",
                "print(f\"ğŸ“¦ ì „ì²´ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {full_model_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {full_model_path.stat().st_size / 1024:.2f} KB\\n\")\n",
                "\n",
                "# ë°©ë²• 3: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (í•™ìŠµ ì¬ê°œìš©)\n",
                "checkpoint_path = save_dir / 'checkpoint.pth'\n",
                "torch.save({\n",
                "    'epoch': 5,\n",
                "    'model_state_dict': model.state_dict(),\n",
                "    'optimizer_state_dict': optimizer.state_dict(),\n",
                "    'loss': avg_loss,\n",
                "}, checkpoint_path)\n",
                "print(f\"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ: {checkpoint_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {checkpoint_path.stat().st_size / 1024:.2f} KB\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2ï¸âƒ£ ì–‘ìí™” (Quantization)\n",
                "## Dynamic Quantization (ë™ì  ì–‘ìí™”) ì¤‘ Eager Mode / Post-Training Quantization\n",
                "### ëª¨ë¸ í¬ê¸° ê°ì†Œ ë° ì¶”ë¡  ì†ë„ í–¥ìƒ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âš¡ ì–‘ìí™” ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: mlp_models\\mission_16_quantized.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 203.44 KB\n",
                        "   ì••ì¶•ë¥ : 3.92x\n",
                        "\n",
                        "âš¡ ì–‘ìí™” ëª¨ë¸ ì „ì²´ ì €ì¥ ì™„ë£Œ: mlp_models\\model_quantized.pth\n",
                        "   íŒŒì¼ í¬ê¸°: 203.98 KB\n",
                        "   ì••ì¶•ë¥ : 3.91x\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# ë™ì  ì–‘ìí™” (Dynamic Quantization)\n",
                "model.eval()\n",
                "quantized_model = torch.quantization.quantize_dynamic(\n",
                "    model,\n",
                "    {nn.Linear},  # ì–‘ìí™”í•  ë ˆì´ì–´ íƒ€ì…\n",
                "    dtype=torch.qint8\n",
                ")\n",
                "\n",
                "# ì–‘ìí™” ëª¨ë¸ ì €ì¥\n",
                "quantized_path = save_dir / 'mission_16_quantized.pth'\n",
                "torch.save(quantized_model.state_dict(), quantized_path)\n",
                "print(f\"âš¡ ì–‘ìí™” ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: {quantized_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {quantized_path.stat().st_size / 1024:.2f} KB\")\n",
                "print(f\"   ì••ì¶•ë¥ : {weights_path.stat().st_size / quantized_path.stat().st_size:.2f}x\\n\")\n",
                "\n",
                "full_quantized_path = save_dir / 'model_quantized.pth'\n",
                "torch.save(quantized_model, full_quantized_path)\n",
                "# torch.save(quantized_model, str(quantized_path) + '_full')\n",
                "# torch.save(quantized_model, quantized_path.with_name(quantized_path.stem + '_full.pth'))\n",
                "print(f\"âš¡ ì–‘ìí™” ëª¨ë¸ ì „ì²´ ì €ì¥ ì™„ë£Œ: {full_quantized_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {full_quantized_path.stat().st_size / 1024:.2f} KB\")\n",
                "print(f\"   ì••ì¶•ë¥ : {full_model_path.stat().st_size / full_quantized_path.stat().st_size:.2f}x\\n\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "FP32 â†’ INT8 ì´ë¡ ì  ìµœëŒ€ ì••ì¶•ë¥  â‰ˆ 4x\n",
                "\n",
                "ê²°ê³¼: 3.9\n",
                "â†’ ê±°ì˜ ì´ë¡ ì  ìµœëŒ€ì¹˜"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3ï¸âƒ£ ONNX ë³€í™˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ”„ ONNX ë³€í™˜ ì™„ë£Œ: mlp_models\\mission_16_model.onnx\n",
                        "   íŒŒì¼ í¬ê¸°: 796.04 KB\n",
                        "\n",
                        "âœ… ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ\n"
                    ]
                }
            ],
            "source": [
                "# ONNXë¡œ ë³€í™˜\n",
                "model.eval()\n",
                "dummy_input = torch.randn(1, 1, 28, 28)  # MNIST ì…ë ¥ í¬ê¸°\n",
                "onnx_path = save_dir / 'mission_16_model.onnx'\n",
                "\n",
                "torch.onnx.export(\n",
                "    model,\n",
                "    dummy_input,\n",
                "    onnx_path,\n",
                "    export_params=True,\n",
                "    opset_version=11,\n",
                "    do_constant_folding=True,\n",
                "    input_names=['input'],\n",
                "    output_names=['output'],\n",
                "    dynamo=False,  # âœ… ë‹¨ì¼ íŒŒì¼ë¡œ ì €ì¥\n",
                "    dynamic_axes={\n",
                "        'input': {0: 'batch_size'},\n",
                "        'output': {0: 'batch_size'}\n",
                "    }\n",
                ")\n",
                "\n",
                "\n",
                "print(f\"ğŸ”„ ONNX ë³€í™˜ ì™„ë£Œ: {onnx_path}\")\n",
                "print(f\"   íŒŒì¼ í¬ê¸°: {onnx_path.stat().st_size / 1024:.2f} KB\\n\")\n",
                "\n",
                "# ONNX ëª¨ë¸ ê²€ì¦\n",
                "onnx_model = onnx.load(onnx_path)\n",
                "onnx.checker.check_model(onnx_model)\n",
                "print(\"âœ… ONNX ëª¨ë¸ ê²€ì¦ ì™„ë£Œ\")\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
