{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumshin-dev/python_conda_jupyter/blob/main/codeit/3_5_7_%E1%84%92%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%87%E1%85%B3%E1%84%85%E1%85%B5%E1%84%83%E1%85%B3%E1%84%80%E1%85%A5%E1%86%B7%E1%84%89%E1%85%A2%E1%86%A8_%E1%84%85%E1%85%B5%E1%84%85%E1%85%A2%E1%86%BC%E1%84%8F%E1%85%B5%E1%86%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê³¼ ë¦¬ë­í‚¹\n",
        "\n"
      ],
      "metadata": {
        "id": "IiOtmI7nlTh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
        "í‚¤ì›Œë“œ ê²€ìƒ‰(Keyword Search)ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰(Semantic Search)ì˜ ì¥ì ì„ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ê¸°ë²•\n",
        "\n",
        "RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œ êµ¬ì¶• ì‹œ, ë‹¨ìˆœíˆ ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš©í•  ê²½ìš° ê³ ìœ ëª…ì‚¬ë‚˜ ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆëŠ”ë°, í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ëŠ” ì´ë¥¼ ë³´ì™„(BM25 â†’ í‚¤ì›Œë“œ ê¸°ë°˜ ì •í™•í•œ ê²€ìƒ‰, Vector Search â†’ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰)\n",
        "\n",
        "### í‚¤ì›Œë“œ ê²€ìƒ‰(Sparse Retriever):\n",
        "\n",
        "- BM25 ì•Œê³ ë¦¬ì¦˜ì´ ëŒ€í‘œì : ë‹¨ì–´ì˜ ë¹ˆë„ì™€ ì—­ë¬¸ì„œ ë¹ˆë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•˜ë©°, ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ì— ê°•í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ì˜ë¯¸ ê²€ìƒ‰(Dense Retriever):\n",
        "\n",
        "- ì„ë² ë”©(Embedding) ë²¡í„° ìœ ì‚¬ë„(Cosine Similarity ë“±)ë¥¼ ê¸°ë°˜: ë‹¨ì–´ê°€ ë‹¬ë¼ë„ ë¬¸ë§¥ì  ì˜ë¯¸ê°€ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ëŠ” ë° ê°•í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "ZK5_Q_8wlqvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community rank_bm25 langchain_openai faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qTDI5Qwvlkzg",
        "outputId": "c32a6f43-7e01-4f1e-9a91-fb6d7697f36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.47)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, rank_bm25, mypy-extensions, marshmallow, faiss-cpu, typing-inspect, dataclasses-json, langchain-text-splitters, langchain_openai, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss-cpu-1.13.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.0.0 langchain_openai-1.1.0 marshmallow-3.26.1 mypy-extensions-1.1.0 rank_bm25-0.2.2 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> LangChainì—ì„œëŠ” EnsembleRetriever í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤ìš° ì‰½ê²Œ í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¼ë°˜ì ì¸ ì¡°í•©ì€ **BM25(í‚¤ì›Œë“œ)**ì™€ **VectorStore(ì˜ë¯¸)**ì˜ ê²°í•©ì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "wgiNnHRTncYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Prompt the user for the OpenAI API key securely\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0BrnLoFn636",
        "outputId": "d69103f0-8719-460b-e3b6-4ab0916e9207"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# 1. ìƒ˜í”Œ ë°ì´í„°\n",
        "docs_list = [\n",
        "    \"ì•„ì´í° 15ì˜ ë°°í„°ë¦¬ ìˆ˜ëª…ì€ 20ì‹œê°„ì…ë‹ˆë‹¤.\",\n",
        "    \"ê°¤ëŸ­ì‹œ S24ëŠ” AI ê¸°ëŠ¥ì´ íƒ‘ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\",\n",
        "    \"ì‚¬ê³¼ëŠ” ë§›ìˆëŠ” ê³¼ì¼ì…ë‹ˆë‹¤.\",\n",
        "    \"ë°°í„°ë¦¬ ì ˆì•½ ëª¨ë“œë¥¼ ì¼œë©´ ì‚¬ìš© ì‹œê°„ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "# 2. BM25 retriever\n",
        "bm25 = BM25Retriever.from_texts(docs_list)\n",
        "bm25.k = 2\n",
        "\n",
        "# 3. Vector retriever\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_texts(docs_list, embedding)\n",
        "vec = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "\n",
        "# 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í•¨ìˆ˜\n",
        "def hybrid_search(query):\n",
        "    bm25_docs = bm25.invoke(query)\n",
        "    vec_docs = vec.invoke(query)\n",
        "\n",
        "    # ì¤‘ë³µ ì œê±° + ì ìˆ˜ ì¬ì •ë ¬\n",
        "    doc_dict = {}\n",
        "\n",
        "    # BM25 ê²°ê³¼ â†’ ê°€ì¤‘ì¹˜ 0.5\n",
        "    for doc in bm25_docs:\n",
        "        doc_dict[doc.page_content] = doc_dict.get(doc.page_content, 0) + 0.5\n",
        "\n",
        "    # Vector ê²°ê³¼ â†’ ê°€ì¤‘ì¹˜ 0.5\n",
        "    for doc in vec_docs:\n",
        "        doc_dict[doc.page_content] = doc_dict.get(doc.page_content, 0) + 0.5\n",
        "\n",
        "    # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬\n",
        "    ranked_docs = sorted(doc_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Document í˜•íƒœë¡œ ë³€í™˜\n",
        "    return [Document(page_content=content) for content, _ in ranked_docs]\n",
        "\n",
        "\n",
        "# 5. LCEL Runnableë¡œ ê°ì‹¸ê¸°\n",
        "hybrid_retriever = RunnableLambda(hybrid_search)\n"
      ],
      "metadata": {
        "id": "YZEUsCXpoXYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ê²€ìƒ‰\n",
        "query = \"ìŠ¤ë§ˆíŠ¸í° ë°°í„°ë¦¬ ì„±ëŠ¥\"\n",
        "docs = hybrid_retriever.invoke(query)\n",
        "\n",
        "for d in docs:\n",
        "    print(\"-\", d.page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlUja7LrqKV4",
        "outputId": "2e3b19e8-232a-4014-8190-1e5043e51dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- ë°°í„°ë¦¬ ì ˆì•½ ëª¨ë“œë¥¼ ì¼œë©´ ì‚¬ìš© ì‹œê°„ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.\n",
            "- ì‚¬ê³¼ëŠ” ë§›ìˆëŠ” ê³¼ì¼ì…ë‹ˆë‹¤.\n",
            "- ì•„ì´í° 15ì˜ ë°°í„°ë¦¬ ìˆ˜ëª…ì€ 20ì‹œê°„ì…ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> BM25 ë¹„ì¤‘ì„ ì¤„ì´ê³  ì‹¶ìœ¼ë©´ ìˆ˜ì¹˜ â†“\n",
        "Vector ë¹„ì¤‘ì„ ë†’ì´ê³  ì‹¶ìœ¼ë©´ ìˆ˜ì¹˜ â†‘\n",
        "\n",
        "ì˜ˆ:\n",
        "\n",
        "ë” ì˜ë¯¸ ê²€ìƒ‰ ì¤‘ì‹¬ â†’ BM25: 0.2, Vector: 0.8\n",
        "\n",
        "ë” í‚¤ì›Œë“œ ì¤‘ì‹¬ â†’ BM25: 0.6, Vector: 0.4"
      ],
      "metadata": {
        "id": "n-0mbPJTqB9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë¦¬ë­í‚¹(Re-ranking): \"ì†ë„ vs ì •í™•ë„\"ì˜ íƒ€í˜‘ì \n",
        "\n",
        "- Retrieval ë‹¨ê³„ (Bi-Encoder):\n",
        "\n",
        "    - ìš°ë¦¬ê°€ ì§€ê¸ˆê¹Œì§€ ë°°ìš´ Vector Searchë‚˜ BM25ì…ë‹ˆë‹¤.\n",
        "    - íŠ¹ì§•: ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„°ë¥¼ ë¹„êµí•˜ë¯€ë¡œ ì†ë„ê°€ ì—„ì²­ ë¹ ë¦…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì§ˆë¬¸ê³¼ ë¬¸ì„œì˜ ë””í…Œì¼í•œ ê´€ê³„ë¥¼ ì™„ë²½íˆ íŒŒì•…í•˜ì§€ëŠ” ëª»í•©ë‹ˆë‹¤. (ëŒ€ëµì ì¸ ìœ ì‚¬ë„)\n",
        "    - ë¹„ìœ : ì„œë¥˜ ì „í˜• (ìˆ˜ì²œ ëª…ì˜ ì§€ì›ì ì¤‘ ìŠ¤í™ì´ ë¹„ìŠ·í•œ 50ëª…ì„ ë¹ ë¥´ê²Œ ì¶”ë ¤ëƒ„)\n",
        "\n",
        "### Re-ranking ë‹¨ê³„ (Cross-Encoder):\n",
        "\n",
        "Retrievalì´ ë½‘ì•„ì˜¨ ìƒìœ„ ë¬¸ì„œ(ì˜ˆ: 50ê°œ)ì™€ ì§ˆë¬¸ì„ **í•˜ë‚˜ì˜ ìŒ(Pair)**ìœ¼ë¡œ ë¬¶ì–´ì„œ AI ëª¨ë¸ì— ì§ì ‘ ë„£ìŠµë‹ˆë‹¤.\n",
        "- íŠ¹ì§•: ë‘ ë¬¸ì¥ì˜ ê´€ê³„ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ë¯€ë¡œ ì •í™•ë„ê°€ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì—°ì‚°ëŸ‰ì´ ë§ì•„ ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤. (ê·¸ë˜ì„œ ì „ì²´ ë¬¸ì„œê°€ ì•„ë‹ˆë¼ ìƒìœ„ 50ê°œë§Œ ê²€ì‚¬í•©ë‹ˆë‹¤.)\n",
        "- ë¹„ìœ : ì‹¬ì¸µ ë©´ì ‘ (ì„œë¥˜ í†µê³¼ì 50ëª…ì„ í•œ ëª…ì”© ìì„¸íˆ ì¸í„°ë·°í•˜ì—¬ ìµœì¢… 3ëª…ì„ ì„ ë°œ)\n",
        "\n",
        "\n",
        "- ìš”ì•½\n",
        "    - Vector DBë¡œ ë¹ ë¥´ê³  ë„“ê²Œ í›„ë³´ë¥¼ ì°¾ê³ (Candidate Generation)\n",
        "    - Cross-Encoderë¡œ ì •ë°€í•˜ê²Œ ìˆœìœ„ë¥¼ ë‹¤ì‹œ ë§¤ê¹ë‹ˆë‹¤(Re-ranking)."
      ],
      "metadata": {
        "id": "Xtmi1V2NqhZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface sentence-transformers rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OHzEfCVkrXpH",
        "outputId": "51a452b4-f0be-44b2-9617-1c87ad71b986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (1.1.0)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.4.47)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-huggingface) (1.3.1)\n",
            "Downloading langchain_huggingface-1.1.0-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: langchain-huggingface\n",
            "Successfully installed langchain-huggingface-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = getpass.getpass(\"HuggingFace Token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMWKAdvjxDdG",
        "outputId": "2a4d76e5-39a1-410c-a408-ae3beab08702"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HuggingFace Token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# ------------------------------\n",
        "# 1. ë¬¸ì„œ ì¤€ë¹„\n",
        "# ------------------------------\n",
        "texts = [\n",
        "    \"ê°•ë‚¨ì—­ì—ì„œ ê°€ê¹Œìš´ ìŠ¤í…Œì´í¬ ë§›ì§‘ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë¶„ìœ„ê¸° ì¢‹ì€ ê³ ê¸° ë ˆìŠ¤í† ë‘ì´ ë§ìŠµë‹ˆë‹¤.\",\n",
        "    \"ì„œìš¸ ê°•ë‚¨ì—­ì—ì„œ íŒŒìŠ¤íƒ€ê°€ ë§›ìˆëŠ” ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í¬ë¦¼, í† ë§ˆí†  íŒŒìŠ¤íƒ€ê°€ ìœ ëª…í•©ë‹ˆë‹¤.\",   # ğŸ¯ ì •ë‹µ\n",
        "    \"ê°•ë‚¨ì—­ ë§›ì§‘ ì „ì²´ ê°€ì´ë“œì…ë‹ˆë‹¤. íŒŒìŠ¤íƒ€ë¶€í„° ê³ ê¸°, í•œì‹ê¹Œì§€ ë‹¤ì–‘í•œ ì‹ë‹¹ì„ í¬í•¨í•©ë‹ˆë‹¤.\",\n",
        "    \"ì„œìš¸ í™ëŒ€ íŒŒìŠ¤íƒ€ ë§›ì§‘ ì¶”ì²œì…ë‹ˆë‹¤. ê°•ë‚¨ì—­ê³¼ëŠ” ê±°ë¦¬ê°€ ê½¤ ìˆìŠµë‹ˆë‹¤.\",\n",
        "    \"ë¶€ì‚° ë‚¨ì²œë™ íŒŒìŠ¤íƒ€ ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë¶€ì‚° ì§€ì—­ ì´íƒˆë¦¬ì•ˆ ë§›ì§‘ ëª¨ìŒì…ë‹ˆë‹¤.\",\n",
        "    \"ì„œìš¸ ê°•ë‚¨ì—­ ì¹´í˜ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë””ì €íŠ¸ì™€ ì»¤í”¼ë¡œ ìœ ëª…í•œ ê³³ì´ ë§ìŠµë‹ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "# ------------------------------\n",
        "# 2. BM25 Retriever\n",
        "# ------------------------------\n",
        "bm25 = BM25Retriever.from_texts(texts)\n",
        "bm25.k = 3\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Vector Retriever\n",
        "# ------------------------------\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
        "vectorstore = FAISS.from_texts(texts, embeddings)\n",
        "vec = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# ------------------------------\n",
        "# 4. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°)\n",
        "# ------------------------------\n",
        "def hybrid_search(query: str):\n",
        "    bm25_docs = bm25.invoke(query)\n",
        "    vec_docs = vec.invoke(query)\n",
        "\n",
        "    scores = {}\n",
        "\n",
        "    # BM25 ê°€ì¤‘ì¹˜ 0.5\n",
        "    for d in bm25_docs:\n",
        "        scores[d.page_content] = scores.get(d.page_content, 0) + 0.5\n",
        "\n",
        "    # Vector ê°€ì¤‘ì¹˜ 0.5\n",
        "    for d in vec_docs:\n",
        "        scores[d.page_content] = scores.get(d.page_content, 0) + 0.5\n",
        "\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [Document(page_content=c) for c, _ in ranked]\n",
        "\n",
        "hybrid_retriever = RunnableLambda(hybrid_search)"
      ],
      "metadata": {
        "id": "_ygRLCc4tJph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 5. Cross-Encoder ë¡œ ì§ì ‘ Re-rank\n",
        "# ------------------------------\n",
        "cross_encoder = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\") #ë¬¸ì¥ ë¹„êµ íŠ¹í™” ëª¨ë¸\n",
        "\n",
        "def rerank_with_cross_encoder(query: str, docs, top_n: int = 1):\n",
        "    # (query, ë¬¸ì„œ) ìŒ ë§Œë“¤ê¸°\n",
        "    pairs = [(query, d.page_content) for d in docs]\n",
        "\n",
        "    scores = list(cross_encoder.score(pairs))   # List[float]\n",
        "\n",
        "    # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
        "    ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in ranked[:top_n]]"
      ],
      "metadata": {
        "id": "dFERNhzFy3Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 6. ë¦¬ë­í‚¹ í…ŒìŠ¤íŠ¸\n",
        "# ------------------------------\n",
        "query = \"ì„œìš¸ ê°•ë‚¨ì—­ íŒŒìŠ¤íƒ€ ë§›ì§‘ ì¶”ì²œ\"\n",
        "candidate_docs = hybrid_retriever.invoke(query)                         # 1ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
        "final_docs = rerank_with_cross_encoder(query, candidate_docs, top_n=1)  # 2ë‹¨ê³„: re-rank\n",
        "\n",
        "for d in final_docs:\n",
        "    print(\"ë‹µë³€: \", d.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWc85VdKtMLA",
        "outputId": "ffac8736-84e8-45c0-d49a-5e020baf7d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‹µë³€:  ì„œìš¸ ê°•ë‚¨ì—­ì—ì„œ íŒŒìŠ¤íƒ€ê°€ ë§›ìˆëŠ” ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í¬ë¦¼, í† ë§ˆí†  íŒŒìŠ¤íƒ€ê°€ ìœ ëª…í•©ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# 7. í…ŒìŠ¤íŠ¸: RAG vs í•˜ì´ë¸Œë¦¬ë“œ vs ë¦¬ë­í¬ ë¹„êµ\n",
        "# ------------------------------\n",
        "query = \"ì„œìš¸ ê°•ë‚¨ì—­ íŒŒìŠ¤íƒ€ ë§›ì§‘ ì¶”ì²œ\"\n",
        "\n",
        "# (1) RAG ê¸°ë³¸: ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš©\n",
        "vec_docs = vec.invoke(query)\n",
        "\n",
        "# (2) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: BM25 + ë²¡í„°\n",
        "hybrid_docs = hybrid_retriever.invoke(query)\n",
        "\n",
        "# (3) í•˜ì´ë¸Œë¦¬ë“œ + CrossEncoder ë¦¬ë­í¬ (ìµœì¢… ë‹µë³€ì— ì“¸ ë¬¸ì„œ 1ê°œ ì„ íƒ)\n",
        "reranked_docs = rerank_with_cross_encoder(query, hybrid_docs, top_n=1)\n",
        "\n",
        "print(\"=== 1. ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš© (RAG ê¸°ë³¸) ===\")\n",
        "for i, d in enumerate(vec_docs, 1):\n",
        "    print(f\"{i}. {d.page_content}\")\n",
        "\n",
        "print(\"\\n=== 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°) ===\")\n",
        "for i, d in enumerate(hybrid_docs, 1):\n",
        "    print(f\"{i}. {d.page_content}\")\n",
        "\n",
        "print(\"\\n=== 3. í•˜ì´ë¸Œë¦¬ë“œ + CrossEncoder ë¦¬ë­í¬ (ìµœì¢… ì„ íƒ ë¬¸ì„œ) ===\")\n",
        "for d in reranked_docs:\n",
        "    print(\"ë‹µë³€ì— ì‚¬ìš©í•  ë¬¸ì„œ:\", d.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSJghzEp0Lz_",
        "outputId": "41fc5416-5a96-4b14-e808-06c7783d6447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 1. ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš© (RAG ê¸°ë³¸) ===\n",
            "1. ì„œìš¸ ê°•ë‚¨ì—­ì—ì„œ íŒŒìŠ¤íƒ€ê°€ ë§›ìˆëŠ” ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í¬ë¦¼, í† ë§ˆí†  íŒŒìŠ¤íƒ€ê°€ ìœ ëª…í•©ë‹ˆë‹¤.\n",
            "2. ì„œìš¸ í™ëŒ€ íŒŒìŠ¤íƒ€ ë§›ì§‘ ì¶”ì²œì…ë‹ˆë‹¤. ê°•ë‚¨ì—­ê³¼ëŠ” ê±°ë¦¬ê°€ ê½¤ ìˆìŠµë‹ˆë‹¤.\n",
            "3. ê°•ë‚¨ì—­ ë§›ì§‘ ì „ì²´ ê°€ì´ë“œì…ë‹ˆë‹¤. íŒŒìŠ¤íƒ€ë¶€í„° ê³ ê¸°, í•œì‹ê¹Œì§€ ë‹¤ì–‘í•œ ì‹ë‹¹ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
            "\n",
            "=== 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°) ===\n",
            "1. ì„œìš¸ í™ëŒ€ íŒŒìŠ¤íƒ€ ë§›ì§‘ ì¶”ì²œì…ë‹ˆë‹¤. ê°•ë‚¨ì—­ê³¼ëŠ” ê±°ë¦¬ê°€ ê½¤ ìˆìŠµë‹ˆë‹¤.\n",
            "2. ì„œìš¸ ê°•ë‚¨ì—­ ì¹´í˜ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë””ì €íŠ¸ì™€ ì»¤í”¼ë¡œ ìœ ëª…í•œ ê³³ì´ ë§ìŠµë‹ˆë‹¤.\n",
            "3. ë¶€ì‚° ë‚¨ì²œë™ íŒŒìŠ¤íƒ€ ë§›ì§‘ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë¶€ì‚° ì§€ì—­ ì´íƒˆë¦¬ì•ˆ ë§›ì§‘ ëª¨ìŒì…ë‹ˆë‹¤.\n",
            "4. ì„œìš¸ ê°•ë‚¨ì—­ì—ì„œ íŒŒìŠ¤íƒ€ê°€ ë§›ìˆëŠ” ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í¬ë¦¼, í† ë§ˆí†  íŒŒìŠ¤íƒ€ê°€ ìœ ëª…í•©ë‹ˆë‹¤.\n",
            "5. ê°•ë‚¨ì—­ ë§›ì§‘ ì „ì²´ ê°€ì´ë“œì…ë‹ˆë‹¤. íŒŒìŠ¤íƒ€ë¶€í„° ê³ ê¸°, í•œì‹ê¹Œì§€ ë‹¤ì–‘í•œ ì‹ë‹¹ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
            "\n",
            "=== 3. í•˜ì´ë¸Œë¦¬ë“œ + CrossEncoder ë¦¬ë­í¬ (ìµœì¢… ì„ íƒ ë¬¸ì„œ) ===\n",
            "ë‹µë³€ì— ì‚¬ìš©í•  ë¬¸ì„œ: ì„œìš¸ ê°•ë‚¨ì—­ì—ì„œ íŒŒìŠ¤íƒ€ê°€ ë§›ìˆëŠ” ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. í¬ë¦¼, í† ë§ˆí†  íŒŒìŠ¤íƒ€ê°€ ìœ ëª…í•©ë‹ˆë‹¤.\n"
          ]
        }
      ]
    }
  ]
}