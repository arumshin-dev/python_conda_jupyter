{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5189482b",
            "metadata": {},
            "source": [
                "# 단일 검증셋"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "ed3fa134",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "모델별 성능 비교:\n",
                        "LinearRegression: MSE=4.15133, RMSE=2.0374823, R2=0.9889754\n",
                        "Ridge: MSE=4.15135, RMSE=2.0374856, R2=0.9889754\n",
                        "Lasso: MSE=4.98499, RMSE=2.2327092, R2=0.9867615\n",
                        "DecisionTree: MSE=9.28422, RMSE=3.0470021, R2=0.9753441\n",
                        "RandomForest: MSE=5.50168, RMSE=2.3455664, R2=0.9853893\n",
                        "GradientBoosting: MSE=4.55405, RMSE=2.1340214, R2=0.9879059\n",
                        "SVR: MSE=6.34949, RMSE=2.5198199, R2=0.9831378\n",
                        "KNN: MSE=6.15409, RMSE=2.4807443, R2=0.9836567\n",
                        "MLP: MSE=4.19943, RMSE=2.0492506, R2=0.9888477\n",
                        "\n",
                        "가장 좋은 모델은: LinearRegression\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "# 1. Load data\n",
                "df = pd.read_csv(\"train.csv\")\n",
                "\n",
                "# 2. 중복 제거\n",
                "df = df.drop_duplicates()\n",
                "\n",
                "# 3. Encoding\n",
                "df['Extracurricular Activities'] = df['Extracurricular Activities'].map({\n",
                "    'Yes': 1,\n",
                "    'No': 0\n",
                "})\n",
                "\n",
                "# 4. Feature / Target 분리\n",
                "X = df.drop(\"Performance Index\", axis=1)\n",
                "y = df[\"Performance Index\"]\n",
                "\n",
                "# 5. Train / Validation split\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# 후보 모델들\n",
                "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.neighbors import KNeighborsRegressor\n",
                "from sklearn.neural_network import MLPRegressor\n",
                "\n",
                "models = {\n",
                "    \"LinearRegression\": LinearRegression(),\n",
                "    \"Ridge\": Ridge(),\n",
                "    \"Lasso\": Lasso(),\n",
                "    \"DecisionTree\": DecisionTreeRegressor(),\n",
                "    \"RandomForest\": RandomForestRegressor(),\n",
                "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
                "    \"SVR\": SVR(),\n",
                "    \"KNN\": KNeighborsRegressor(),\n",
                "    \"MLP\": MLPRegressor(max_iter=500)\n",
                "}\n",
                "\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train, y_train)\n",
                "    pred = model.predict(X_val)\n",
                "    results[name] = {\n",
                "        \"MSE\": mean_squared_error(y_val, pred),\n",
                "        \"RMSE\": np.sqrt(mean_squared_error(y_val, pred)),\n",
                "        \"R2\": r2_score(y_val, pred)\n",
                "    }\n",
                "\n",
                "print(\"모델별 성능 비교:\")\n",
                "for name, metrics in results.items():\n",
                "    print(f\"{name}: MSE={metrics['MSE']:.5f}, RMSE={metrics['RMSE']:.7f}, R2={metrics['R2']:.7f}\")\n",
                "\n",
                "best_model_name = max(results, key=lambda name: results[name][\"R2\"])\n",
                "print(f\"\\n가장 좋은 모델은: {best_model_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9dcd347a",
            "metadata": {},
            "source": [
                "단일 검증셋 평가: 데이터 분할 방식에 따라 특정 모델이 우연히 더 잘 맞을 수 있습니다. LinearRegression이 그 검증셋에서는 가장 높은 R²을 보였죠."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a539affd",
            "metadata": {},
            "source": [
                "# 교차 검증"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "aa81a4b1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "교차검증 결과:\n",
                        "LinearRegression: 평균 R2=0.9885741354, 표준편차=0.0003281541\n",
                        "Ridge: 평균 R2=0.9885741376, 표준편차=0.0003281852\n",
                        "Lasso: 평균 R2=0.9866697053, 표준편차=0.0004827954\n",
                        "DecisionTree: 평균 R2=0.9741508725, 표준편차=0.0005806524\n",
                        "RandomForest: 평균 R2=0.9850015572, 표준편차=0.0005855513\n",
                        "GradientBoosting: 평균 R2=0.9876300454, 표준편차=0.0004224029\n",
                        "SVR: 평균 R2=0.9828817213, 표준편차=0.0003310369\n",
                        "KNN: 평균 R2=0.9824500548, 표준편차=0.0004358799\n",
                        "MLP: 평균 R2=0.9883483977, 표준편차=0.0004383721\n",
                        "\n",
                        "가장 좋은 모델은: Ridge\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from sklearn.model_selection import cross_val_score\n",
                "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.neighbors import KNeighborsRegressor\n",
                "from sklearn.neural_network import MLPRegressor\n",
                "\n",
                "# 데이터 로드\n",
                "train_df = pd.read_csv(\"train.csv\")\n",
                "train_df = train_df.drop_duplicates()\n",
                "train_df['Extracurricular Activities'] = train_df['Extracurricular Activities'].map({\n",
                "    'Yes': 1,\n",
                "    'No': 0\n",
                "})\n",
                "X = train_df.drop(columns=[\"Performance Index\"])\n",
                "y = train_df[\"Performance Index\"]\n",
                "\n",
                "# 후보 모델들\n",
                "models = {\n",
                "    \"LinearRegression\": LinearRegression(),\n",
                "    \"Ridge\": Ridge(),\n",
                "    \"Lasso\": Lasso(),\n",
                "    \"DecisionTree\": DecisionTreeRegressor(),\n",
                "    \"RandomForest\": RandomForestRegressor(),\n",
                "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
                "    \"SVR\": SVR(),\n",
                "    \"KNN\": KNeighborsRegressor(),\n",
                "    \"MLP\": MLPRegressor(max_iter=500)\n",
                "}\n",
                "\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    # 교차검증 (5-fold, R^2 기준)\n",
                "    scores = cross_val_score(model, X, y, cv=5, scoring=\"r2\")\n",
                "    results[name] = {\n",
                "        \"mean_R2\": scores.mean(),\n",
                "        \"std_R2\": scores.std()\n",
                "    }\n",
                "\n",
                "print(\"교차검증 결과:\")\n",
                "for name, metrics in results.items():\n",
                "    print(f\"{name}: 평균 R2={metrics['mean_R2']:.10f}, 표준편차={metrics['std_R2']:.10f}\")\n",
                "\n",
                "best_model_name = max(results, key=lambda name: results[name][\"mean_R2\"])\n",
                "print(f\"\\n가장 좋은 모델은: {best_model_name}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c910693",
            "metadata": {},
            "source": [
                "# 교차검증 + 하이퍼파라미터 튜닝(GridSearchCV)으로 Ridge의 최적 알파 값을 찾아주는 코드"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "5f286571",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "최적 하이퍼파라미터: {'alpha': 1}\n",
                        "최적 평균 R²: 0.9885741376473879\n",
                        "최적 모델: Ridge(alpha=1)\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from sklearn.linear_model import Ridge\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "import os\n",
                "os.environ[\"JOBLIB_TEMP_FOLDER\"] = \"E:\\\\temp\"\n",
                "\n",
                "# 데이터 로드\n",
                "train_df = pd.read_csv(\"train.csv\")\n",
                "train_df = train_df.drop_duplicates()\n",
                "train_df['Extracurricular Activities'] = train_df['Extracurricular Activities'].map({\n",
                "    'Yes': 1,\n",
                "    'No': 0\n",
                "})\n",
                "X = train_df.drop(columns=[\"Performance Index\"])\n",
                "y = train_df[\"Performance Index\"]\n",
                "\n",
                "# Ridge 모델 정의\n",
                "ridge = Ridge()\n",
                "\n",
                "# 탐색할 alpha 값 범위 설정\n",
                "param_grid = {\n",
                "    \"alpha\": [0.01, 0.1, 1, 10, 100, 1000]\n",
                "}\n",
                "\n",
                "# GridSearchCV 설정 (5-fold 교차검증, R² 기준)\n",
                "grid_search = GridSearchCV(\n",
                "    estimator=ridge,\n",
                "    param_grid=param_grid,\n",
                "    cv=5,\n",
                "    scoring=\"r2\",\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "# 학습\n",
                "grid_search.fit(X, y)\n",
                "\n",
                "# 결과 출력\n",
                "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
                "print(\"최적 평균 R²:\", grid_search.best_score_)\n",
                "print(\"최적 모델:\", grid_search.best_estimator_)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "67e7319f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "최적 하이퍼파라미터: {'alpha': np.float64(6.158482110660261)}\n",
                        "최적 평균 R²: 0.9885741418135519\n",
                        "최적 모델: Ridge(alpha=np.float64(6.158482110660261))\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.linear_model import Ridge\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# 데이터 로드\n",
                "train_df = pd.read_csv(\"train.csv\")\n",
                "train_df = train_df.drop_duplicates()\n",
                "train_df['Extracurricular Activities'] = train_df['Extracurricular Activities'].map({\n",
                "    'Yes': 1,\n",
                "    'No': 0\n",
                "})\n",
                "X = train_df.drop(columns=[\"Performance Index\"])\n",
                "y = train_df[\"Performance Index\"]\n",
                "\n",
                "# Ridge 모델 정의\n",
                "ridge = Ridge()\n",
                "\n",
                "# alpha 값을 로그 스케일로 세밀하게 탐색\n",
                "param_grid = {\n",
                "    \"alpha\": np.logspace(-3, 3, 20)  # 0.001 ~ 1000 사이에서 20개 값\n",
                "}\n",
                "\n",
                "# GridSearchCV 설정 (5-fold 교차검증, R² 기준)\n",
                "grid_search = GridSearchCV(\n",
                "    estimator=ridge,\n",
                "    param_grid=param_grid,\n",
                "    cv=5,\n",
                "    scoring=\"r2\",\n",
                "    n_jobs=1   # Windows 환경에서 인코딩 문제 피하려면 병렬 끄기\n",
                ")\n",
                "\n",
                "# 학습\n",
                "grid_search.fit(X, y)\n",
                "\n",
                "# 결과 출력\n",
                "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
                "print(\"최적 평균 R²:\", grid_search.best_score_)\n",
                "print(\"최적 모델:\", grid_search.best_estimator_)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fdeb276e",
            "metadata": {},
            "source": [
                "# 스케일링"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "e5067206",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "단일 검증셋 결과:\n",
                        "LinearRegression: RMSE=2.0375, R2=0.98898\n",
                        "Ridge: RMSE=2.0382, R2=0.98897\n",
                        "Lasso: RMSE=2.7588, R2=0.97979\n",
                        "DecisionTree: RMSE=3.0881, R2=0.97467\n",
                        "RandomForest: RMSE=2.3392, R2=0.98547\n",
                        "GradientBoosting: RMSE=2.1340, R2=0.98791\n",
                        "SVR: RMSE=2.4640, R2=0.98388\n",
                        "KNN: RMSE=3.0790, R2=0.97482\n",
                        "MLP: RMSE=2.1070, R2=0.98821\n",
                        "\n",
                        "가장 높은 R2: LinearRegression\n",
                        "\n",
                        "가장 낮은 오차: LinearRegression\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.pipeline import Pipeline\n",
                "\n",
                "# 모델들\n",
                "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.neighbors import KNeighborsRegressor\n",
                "from sklearn.neural_network import MLPRegressor\n",
                "\n",
                "# 1. Load & preprocess\n",
                "df = pd.read_csv(\"train.csv\").drop_duplicates()\n",
                "df['Extracurricular Activities'] = df['Extracurricular Activities'].map({'Yes': 1, 'No': 0})\n",
                "\n",
                "X = df.drop(\"Performance Index\", axis=1)\n",
                "y = df[\"Performance Index\"]\n",
                "\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "# 2. Pipeline 기반 모델 정의\n",
                "models = {\n",
                "    \"LinearRegression\": Pipeline([\n",
                "        (\"scaler\", StandardScaler()),\n",
                "        (\"model\", LinearRegression())\n",
                "    ]),\n",
                "    \"Ridge\": Pipeline([\n",
                "        (\"scaler\", StandardScaler()),\n",
                "        (\"model\", Ridge(alpha=6.158482110660261))\n",
                "    ]),\n",
                "    \"Lasso\": Pipeline([\n",
                "        (\"scaler\", StandardScaler()),\n",
                "        (\"model\", Lasso())\n",
                "    ]),\n",
                "    \"DecisionTree\": DecisionTreeRegressor(),\n",
                "    \"RandomForest\": RandomForestRegressor(random_state=42),\n",
                "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
                "    \"SVR\": Pipeline([\n",
                "        (\"scaler\", StandardScaler()),\n",
                "        (\"model\", SVR())\n",
                "    ]),\n",
                "    \"KNN\": Pipeline([\n",
                "        (\"scaler\", StandardScaler()),\n",
                "        (\"model\", KNeighborsRegressor())\n",
                "    ]),\n",
                "    \"MLP\": Pipeline([\n",
                "        (\"scaler\", StandardScaler()),\n",
                "        (\"model\", MLPRegressor(max_iter=500, random_state=42))\n",
                "    ])\n",
                "}\n",
                "\n",
                "# 3. 평가\n",
                "results = {}\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train, y_train)\n",
                "    pred = model.predict(X_val)\n",
                "    results[name] = {\n",
                "        \"RMSE\": np.sqrt(mean_squared_error(y_val, pred)),\n",
                "        \"R2\": r2_score(y_val, pred)\n",
                "    }\n",
                "\n",
                "print(\"단일 검증셋 결과:\")\n",
                "for k, v in results.items():\n",
                "    print(f\"{k}: RMSE={v['RMSE']:.4f}, R2={v['R2']:.5f}\")\n",
                "max_r2 = max(results, key=lambda name: results[name][\"R2\"])\n",
                "min_rmse = min(results, key=lambda name: results[name][\"RMSE\"])\n",
                "print(f\"\\n가장 높은 R2: {max_r2}\")\n",
                "print(f\"\\n가장 낮은 오차: {min_rmse}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "fc24871e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "5-Fold 교차검증 결과 (R²):\n",
                        "LinearRegression: 평균=0.98857, 표준편차=0.00033\n",
                        "Ridge: 평균=0.98857, 표준편차=0.00033\n",
                        "Lasso: 평균=0.98002, 표준편차=0.00046\n",
                        "DecisionTree: 평균=0.97404, 표준편차=0.00070\n",
                        "RandomForest: 평균=0.98499, 표준편차=0.00055\n",
                        "GradientBoosting: 평균=0.98763, 표준편차=0.00042\n",
                        "SVR: 평균=0.98337, 표준편차=0.00025\n",
                        "KNN: 평균=0.97252, 표준편차=0.00057\n",
                        "MLP: 평균=0.98801, 표준편차=0.00028\n",
                        "\n",
                        "가장 좋은 모델은: LinearRegression\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import cross_val_score\n",
                "\n",
                "print(\"\\n5-Fold 교차검증 결과 (R²):\")\n",
                "\n",
                "cv_results = {}\n",
                "for name, model in models.items():\n",
                "    scores = cross_val_score(model, X, y, cv=5, scoring=\"r2\")\n",
                "    # cv_results[name] = (scores.mean(), scores.std())\n",
                "    cv_results[name] = {\n",
                "        \"mean_R2\": scores.mean(),\n",
                "        \"std_R2\": scores.std()\n",
                "    }\n",
                "    print(f\"{name}: 평균={scores.mean():.5f}, 표준편차={scores.std():.5f}\")\n",
                "\n",
                "best_model_name = max(cv_results, key=lambda name: cv_results[name]['mean_R2'])\n",
                "print(f\"\\n가장 좋은 모델은: {best_model_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e6ef4cc",
            "metadata": {},
            "source": [
                "초기 단일 검증 셋 평가에서는 Linear Regression이 가장 우수한 성능을 보였다.\n",
                "이후 교차검증 결과에서 Ridge Regression이 매우 근소하게 높은 평균 R²를 기록하여,\n",
                "정규화 효과에 따른 일반화 성능 개선 가능성을 검토하였다. 이에 따라 Ridge 모델에 대해 하이퍼파라미터 튜닝을 수행하였으며,\n",
                "alpha ≈ 6.16에서 최적의 교차검증 성능을 확인하였다.\n",
                "\n",
                "그러나 컬럼 간 값의 범위 차이를 고려하여 표준화(Standard Scaling)를 적용한 후,\n",
                "단일 검증 셋 평가와 5-Fold 교차검증을 다시 수행한 결과,\n",
                "Linear Regression과 Ridge Regression은 성능 차이가 사실상 없는 수준으로 수렴하였다.\n",
                "특히 Linear Regression은 Ridge와 동일한 평균 R²와 유사한 분산을 보이면서도,\n",
                "추가적인 하이퍼파라미터 튜닝이 필요 없는 가장 단순한 구조를 유지하였다.\n",
                "\n",
                "이에 따라 본 프로젝트에서는\n",
                "성능, 안정성, 해석 용이성, 모델 단순성을 종합적으로 고려하여\n",
                "초기 실험에서 확인된 Linear Regression 모델을 최종 모델로 유지하였다."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "torch_gpu",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
